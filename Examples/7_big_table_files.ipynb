{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with \"Big Table\" Datafiles\n",
    "\n",
    "This notebook gives an example how to read \"Big Table\" datafiles using `qpcr.Readers`.\n",
    "It makes use of the provided example data in the `Example Data` directory. \n",
    "\n",
    "\n",
    "#### Experimental background\n",
    "\n",
    "The corresponding experimental setup was as follows: \n",
    "Levels of Nonsense-mediated mRNA decay (NMD) sensitive (nmd) and insensitive (prot) transcript isoforms of HNRNPL and SRSF11 were measured by qPCR. As normalisers both 28S rRNA and Actin transcript levels were measured. The replicates are biological triplicates and technical douplicates. All measurements from the same qPCR sample were merged into hexaplicates (6 replicates). This was done in two separate HeLa cell lines (one with a specific gene knockout (KO), and one without (WT)), which were both treated to a plasmid-mediated rescue (+) or not (-), leading to four experimental conditions:\n",
    "\n",
    "\n",
    "| cell line \\\\ condition | rescue | no rescue |\n",
    "| ---------------------- | ------ | --------- |\n",
    "| knockout               | KO+    | KO-       |\n",
    "| wildtype               | WT+    | WT-       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the qpcr module\n",
    "import qpcr\n",
    "from qpcr.Readers import BigTableReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Reading a \"vertical\" Big Table File\n",
    "---\n",
    "\n",
    "### 1.1 Setting up the `DataReader`\n",
    "First we set up the `qpcr.DataReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our single-assay datafile\n",
    "file = \"./Example Data/Big Table Files/vertical_bigtable_decorated.csv\"\n",
    "\n",
    "# set up the reader\n",
    "reader = qpcr.DataReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Specify how to read the file\n",
    "\n",
    "This datafile is a \"vertical\" Big Table file. That means it stores assays above each other and has an `assay`, a `sample` (groups), and `Ct` column. In fact, this example datafile has nothing else in it, but reading a file that specifies other stuff would work just the same. \n",
    "\n",
    "In order to read Big Table file we need to specify `big_table = True` for the `DataReader` or immediately use the `qpcr.Readers.BigTableReader`.\n",
    "\n",
    "#### The `kind` parameter\n",
    "One important parameter we have to specify is the architecture of the table. The table in our file is \"vertical\" so we need to specify `kind = \"vertical\"` in order to tell the `Reader` how to interpret the data it reads. The `kind` parameter tells the `BigTableReader` which parsing method to use to extract the individual assays. The other option here would correspondingly be `kind = \"horizontal\"`.\n",
    "\n",
    "Also, note how the filename already has \"decorated\" in it? That's because the file already includes a `@qpcr` decorator column specifying which assays are \"assays-of-interest\" and which ones are normalisers. \n",
    "\n",
    "Like this we can read the file and immediately pass it on to our analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assay(id='HNRNPL nmd', eff=1.0, n=24), Assay(id='HNRNPL prot', eff=1.0, n=24)] [Assay(id='28S', eff=1.0, n=24)]\n"
     ]
    }
   ],
   "source": [
    "assays, normalisers = reader.read(\n",
    "                                        filename = file, \n",
    "\n",
    "                                        # specify the big table\n",
    "                                        big_table = True,\n",
    "\n",
    "                                        # specify that the data is decorated\n",
    "                                        decorator = True,\n",
    "\n",
    "                                        # specify the kind of big table\n",
    "                                        kind = \"vertical\",\n",
    "\n",
    "                                        # specify which columns store\n",
    "                                        # the relevant data\n",
    "                                        assay_col = \"Assay\", \n",
    "                                        id_col = \"Name\",\n",
    "                                        ct_col = \"Ct\"\n",
    "                        )\n",
    "# which yields\n",
    "print( assays, normalisers )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Using the `qpcr.Readers.BigTableReader` directly\n",
    "\n",
    "Of course, we can, again, also use the `BigTableReader` directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = BigTableReader()\n",
    "\n",
    "# read the file\n",
    "assays, normalisers = reader.pipe(\n",
    "                                        filename = file, \n",
    "\n",
    "                                        # specify that the data is decorated\n",
    "                                        decorator = True,\n",
    "\n",
    "                                        # specify the kind of big table\n",
    "                                        kind = \"vertical\",\n",
    "\n",
    "                                        # specify which columns store\n",
    "                                        # the relevant data\n",
    "                                        assay_col = \"Assay\", \n",
    "                                        id_col = \"Name\",\n",
    "                                        ct_col = \"Ct\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Reading a \"horizontal\" Big Table File\n",
    "----------------------------------------------------------------\n",
    "\n",
    "Reading a \"horizontal\" big table file is actually much more tricky than it's vertical counterpart. Why's that? Well, because in \"horizontal\" big table files the replicates are aligned in columns next to each other, and they usually have different column headers as well. That means we can no longer rely on a single column or even a specific `regex` pattern to extract our values. Instead we need to rely on `qpcr decorators` to help guide the parsing algorithm. To this end, we have the `@qpcr:group` decorator, which has to be placed _in the cell immediately above the first replicate column of each group_. Sounds too abstract? Check out the the `Getting Started` notebook again and look at the example there (it's actually not complicated at all).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Using the `BigTableReader`\n",
    "\n",
    "We will actually now read a datafile that is not one of our normal example files. It's a file from [Yang et al. (2018)](https://doi.org/10.5061/dryad.3274k) who analysed the expression of micro-RNAs (miRNAs) in alvular interstitial cells of dogs suffering from Canine myxomatous mitral valve disease. The architecture of the datafile they uploaded to Zenodo is a \"horizontal\" big table containing assays of miRNAs on separate rows and replicate Ct values from \"normal\" (healthy), \"mildly\" ill, or \"severely\" ill dogs as three replicate groups of five replicates each. \n",
    "\n",
    "Regrettably, they did not include the Ct values from the normaliser assays they used, so we will be unable to to anything useful beyond \"file reading\".\n",
    "\n",
    "> Please, note that the datafile we are reading is actually a processed version of the original file they uploaded that merged the separate sheets from the excel file into a single-sheet big table. Also, duplicate assays were dropped for the purpose of reading. Currently, the `BigTableReader` in `\"horizontal\"` parsing mode only supports *uniquely* labelled assays (so if there _are_ duplicate assays they must be differently labelled!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded assays: 286\n"
     ]
    }
   ],
   "source": [
    "file = \"./Example Data/Big Table Files/horizontal_bigtable_decorated.csv\"\n",
    "\n",
    "# we need to reset the reader, because \n",
    "# it currently still stores the assays \n",
    "# from the vertical big table file...\n",
    "reader.clear()\n",
    "\n",
    "assays, normalisers = reader.pipe(\n",
    "                                    filename = file,\n",
    "\n",
    "                                    # we specify that it's a horizontal table\n",
    "                                    kind = \"horizontal\",\n",
    "\n",
    "                                    # we **have to** specify the \n",
    "                                    # number of replicates per group\n",
    "                                    replicates = 5,\n",
    "\n",
    "                                    # we also specify the group names (because they \n",
    "                                    # will not be inferrable due to the different \n",
    "                                    # column names of the replicates)\n",
    "                                    names = [\"normal\", \"mild\", \"severe\"],\n",
    "                                    \n",
    "                                    # we must also specify which column specifies the assays\n",
    "                                    # NOTE: in this mode this is handled by the `id_col` argument!\n",
    "                                    id_col = \"Target\"\n",
    "                                \n",
    "                                )\n",
    "\n",
    "print( f\"Loaded assays: {len(assays)}\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like this we have read 286 new `qpcr.Assay`s that we can now either process through native `qpcr` methods, or we can use the data we just assembled with external tools such as `pandas`, `scipy`, or `numpy`. After all, there is no need to restrict ourselves to using `qpcr` only for its developed \"core business\" of Delta-Delta-Ct analysis. We can use the data `qpcr` reads for any kind of analysis we want."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2734b62963039aeeb60b771e82b61c77981815502f674c850ca7bca72bab0171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
