<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>qpcr.Readers.Readers API documentation</title>
<meta name="description" content="This module provides different `Reader` classes that allow reading simple and complex datafiles
of various architectures …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>qpcr.Readers.Readers</code></h1>
</header>
<section id="section-intro">
<p>This module provides different <code>Reader</code> classes that allow reading simple and complex datafiles
of various architectures.</p>
<h2 id="available-data-readers">Available Data Readers</h2>
<hr>
<h3 id="singlereader">SingleReader</h3>
<p>The <code><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></code> is able to read both regular and irregular single-assay datafiles.
It can also read multi-assay datafiles but requires an <code>assay</code> argument, specifying
which assay specifically to extract from it.</p>
<h3 id="multireader">MultiReader</h3>
<p>The <code><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></code> can read irregular multi-assay datafiles and extract all assays from them
either using a specific <code>assay_pattern</code> to find them or using <code>decorators</code> (check out the documentation
of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code> for more information).</p>
<h3 id="multisheetreader">MultiSheetReader</h3>
<p>The <code><a title="qpcr.Readers.Readers.MultiSheetReader" href="#qpcr.Readers.Readers.MultiSheetReader">MultiSheetReader</a></code> is able to read irregular multi-assay datafiles that contain assays in multiple
datasheets.</p>
<h3 id="bigtablereader">BigTableReader</h3>
<p>The <code><a title="qpcr.Readers.Readers.BigTableReader" href="#qpcr.Readers.Readers.BigTableReader">BigTableReader</a></code> is able to read datafiles that store their assays in one single "big table". It
can extract all assays from that big table using either simple extraction methods or <code>decorators</code> depending
on the type of big table (check out the documentation of the <code><a title="qpcr.Readers.Readers.BigTableReader" href="#qpcr.Readers.Readers.BigTableReader">BigTableReader</a></code> for more information on the
types of "big tables").</p>
<blockquote>
<h3 id="kwarg-incompatibility-warning">Kwarg incompatibility Warning</h3>
<p>When using the <code><a title="qpcr.DataReader" href="../index.html#qpcr.DataReader">DataReader</a></code> or a <code>pipe</code> method you will regularly observe the following warning: </p>
<p><code>Warning:
It appears as if some provided kwargs were incompatible with pandas.read_excel()! Defaulting to standard settings for file-reading...
If the kwargs you specified are actually important for file reading, try manually reading and parsing to avoid kwarg incompatibilities.</code></p>
<p>This is because the <code>pipe</code> method (and the <code><a title="qpcr.DataReader" href="../index.html#qpcr.DataReader">DataReader</a></code>, which usually calls the <code>pipe</code> method of a specific Reader) pass all kwargs to both <code>read</code> and <code>parse</code>.
However, <code>pandas</code>' <code>read_excel</code> and <code>read_csv</code> are rather picky with the arguments they accept. So, in case you observe this warning, just know that the kwargs were removed from the
<code>read</code> call.</p>
</blockquote>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module provides different `Reader` classes that allow reading simple and complex datafiles
of various architectures.

## Available Data Readers
---

### SingleReader
The `SingleReader` is able to read both regular and irregular single-assay datafiles. 
It can also read multi-assay datafiles but requires an `assay` argument, specifying
which assay specifically to extract from it.

### MultiReader
The `MultiReader` can read irregular multi-assay datafiles and extract all assays from them
either using a specific `assay_pattern` to find them or using `decorators` (check out the documentation
of the `qpcr.Parsers` for more information).

### MultiSheetReader
The `MultiSheetReader` is able to read irregular multi-assay datafiles that contain assays in multiple 
datasheets.

### BigTableReader
The `BigTableReader` is able to read datafiles that store their assays in one single &#34;big table&#34;. It
can extract all assays from that big table using either simple extraction methods or `decorators` depending
on the type of big table (check out the documentation of the `BigTableReader` for more information on the
types of &#34;big tables&#34;).


&gt; ### Kwarg incompatibility Warning
&gt; When using the `qpcr.DataReader` or a `pipe` method you will regularly observe the following warning: 
&gt; 
&gt; ```
&gt; Warning:
&gt; It appears as if some provided kwargs were incompatible with pandas.read_excel()! Defaulting to standard settings for file-reading...
&gt; If the kwargs you specified are actually important for file reading, try manually reading and parsing to avoid kwarg incompatibilities.
&gt; ```
&gt;
&gt; This is because the `pipe` method (and the `qpcr.DataReader`, which usually calls the `pipe` method of a specific Reader) pass all kwargs to both `read` and `parse`. 
&gt; However, `pandas`&#39; `read_excel` and `read_csv` are rather picky with the arguments they accept. So, in case you observe this warning, just know that the kwargs were removed from the 
&gt; `read` call.
&#34;&#34;&#34;


# Concept to link the Readers to the DataReader
# All Readers define a _DataReader method that 
# specifies which of its methods is supposed 
# to be used for (mostly pipe, sometimes read...)
# _DataReader methods *must* return the data they read!

from attr import asdict
import pandas as pd
import qpcr
import qpcr._auxiliary as aux
from qpcr._auxiliary import warnings as aw
import qpcr._auxiliary.defaults as defaults
import qpcr.Parsers as Parsers
import os
import numpy as np 
from copy import deepcopy 
from io import StringIO
import re 


__pdoc__ = {
    &#34;_CORE_Reader&#34; : True
}

# migrate default settings from __init__
raw_col_names = defaults.raw_col_names
supported_filetypes = defaults.supported_filetypes
default_dataset_header = defaults.default_dataset_header
default_id_header = defaults.default_id_header
default_ct_header = defaults.default_ct_header
class _CORE_Reader(aux._ID):
    &#34;&#34;&#34;
    The class handling the core functions of the Reader class. 
    Both the standard qpcr.Reader as well as the qpcr._Qupid_Reader
    inherit from this. 
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()
        self._src = None
        self._delimiter = None
        self._header = 0
        self._df = None
        self._replicates = None
        self._names = None


    def get(self):
        &#34;&#34;&#34;
        Returns
        -------
        data : pd.DataFrame
            The dataframe from the datafile.
        &#34;&#34;&#34;
        return self._df

    def n(self):
        &#34;&#34;&#34;
        Returns
        -------
        n : int
            The number of replicates (entries) in the dataframe.
        &#34;&#34;&#34;
        return len(self._df[raw_col_names[0]])

    def make_Assay(self):
        &#34;&#34;&#34;
        Converts the extracted dataset into an `qpcr.Assay`.
        Returns
        --------
        Assay : qpcr.Assay
            The `qpcr.Assay` from the extracted dataset.
        &#34;&#34;&#34;
        assay = self._make_new_Assay(self.id(), self._df)
        return assay

    def read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file.

        If the data file is an Excel file replicates and their Ct values will be 
        extracted from the first excel sheet of the file. Note, this assumes by default
        that the replicates are headed by the label `&#34;Name&#34;` and the corresponding Ct values
        are headed by the label `&#34;Ct&#34;`. Both labels have to be on the same row. 

        If these labels do not match your excel file, you may
        specify `id_label` and `ct_label` as additional arguments.
        &#34;&#34;&#34;
        suffix = self._filesuffix()
        # check for a valid input file
        if suffix not in supported_filetypes:
            aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

        if suffix == &#34;csv&#34;:
            
            # first try simple read of &#34;regular files&#34;
            try: 
                self._csv_read(**kwargs)
            except Exception as e:

                # users can force-regular reading mode
                is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
                if is_regular:
                    # print out warning
                    print(e)
                    return

                # setup parser
                parser = Parsers.CsvParser()
                self._prep_Parser(kwargs, parser)
                
                assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
                
                # pipe the datafile through the parser
                parser.pipe(self._src, **kwargs)

                # get the data
                self._get_single_assay(parser, assay_of_interest)

        elif suffix == &#34;xlsx&#34;:

            try: 
                self._excel_read(**kwargs)
            except Exception as e:

                # users can force-regular reading mode
                is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
                if is_regular:
                    # print out warning
                    print(e)
                    return

                # setup parser
                parser = Parsers.ExcelParser()
                self._prep_Parser(kwargs, parser)
                
                # check for sheet_name
                sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)

                # store assay-of-interest
                assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
                
                # pipe the datafile through the parser
                parser.read(self._src, sheet_name = sheet_name)
                parser.parse(**kwargs)

                # get the data
                self._get_single_assay(parser, assay_of_interest)

    def names(self, names:(list or dict)):
        &#34;&#34;&#34;
        Set names for replicates groups.

        Parameters
        ----------
        names : list or dict
            Either a `list` (new names without repetitions) or `dict` (key = old name, value = new name) specifying new group names. 
            Group names only need to be specified once, and are applied to all replicate entries.
        &#34;&#34;&#34;
        if names is not None: 
            self._names = names
        return self._names

    def replicates(self, replicates : (int or tuple or str) = None):
        &#34;&#34;&#34;
        Either sets or gets the replicates settings to be used for grouping
        Before they are assigned, replicates are vetted to ensure they cover all data entries.

        Parameters
        ----------
        replicates : int or tuple or str
            Can be an `integer` (equal group sizes, e.g. `3` for triplicates), 
            or a `tuple` (uneven group sizes, e.g. `(3,2,3)` if the second group is only a duplicate). 
            Another method to achieve the same thing is to specify a &#34;formula&#34; as a string of how to create a replicate tuple.
            The allowed structure of such a formula is `n:m,` where `n` is the number of replicates in a group and `m` is the number of times
            this pattern is repeated (if no `:m` is specified `:1` is assumed). So, as an example, if there are 12 groups which are triplicates, but
            at the end there is one which only has a single replicate (like the commonly measured diluent qPCR sample), we could either specify the tuple
            individually as `replicates = (3,3,3,3,3,3,3,3,3,3,3,3,1)` or we use the formula to specify `replicates = &#34;3:12,1&#34;`. Of course, this works for
            any arbitrary setting such as `&#34;3:5,2:5,10,3:12&#34;` (which specifies five triplicates, followed by two duplicates, a single decaplicate, and twelve triplicates again – truly a dataset from another dimension)...
        &#34;&#34;&#34;
        if replicates is not None:
            self._replicates = replicates
        return self._replicates

    def _get_single_assay(self, parser, assay_of_interest):
        &#34;&#34;&#34;
        Gets a single dataset from the Parser
        &#34;&#34;&#34;

        # check if there are multiple datasets
        # and if so, check if we got a specified assay_of_interest
        if len(parser.assays()) &gt; 1:
            
            if assay_of_interest is None: 
                aw.HardWarning(&#34;Reader:cannot_read_multifile&#34;, file = self._src, assays = parser.assays(), traceback = False)
            self._df = parser.get(assay_of_interest)
            self.id_reset()
            self.id(assay_of_interest)

        # if only one assay is present anyway, get that one
        else:

            assay_of_interest = parser.assays()[0]
            self._df = parser.get(assay_of_interest)
            self.id_reset()
            self.id(assay_of_interest)

    def _prep_Parser(self, kwargs, parser):
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            parser.transpose()
                
        # setup patterns and store assay-of-interest
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, &#34;Rotor-Gene&#34;, kwargs)
        parser.assay_pattern(assay_pattern)
                
        # get data column labels
        id_label = aux.from_kwargs(&#34;id_label&#34;, &#34;Name&#34;, kwargs, rm = True)
        ct_label = aux.from_kwargs(&#34;ct_label&#34;, &#34;Ct&#34;, kwargs, rm = True)
        parser.labels(id_label,ct_label)
  
    def _csv_read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file if it&#39;s a csv file

        This is the basic default reading method for 
        regular csv files.
        &#34;&#34;&#34;
        df = None
        # header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm  = True)
        try: 
            df = pd.read_csv(
                                self._src, 
                                sep = self._delimiter, 
                                header = self._header, 
                                # names = raw_col_names
                            )
        except: 
            aw.HardWarning(&#34;Reader:cannot_read_csv&#34;, file = self._src)


        # try to get a FileID, from the kwargs
        # if that fails, try to get the one from fileID
        id = aux.from_kwargs(&#34;id&#34;, None, kwargs, rm = True)
        if id is not None:
            self.id_reset()
            self.id(id)
        elif isinstance(self._src, str):
            self.id_reset()
            self.id(aux.fileID(self._src))
        
        # vet and crop the dataframe where necessary
        df = self._vet_single_assay_df(kwargs, df)

        self._df = df

    def _excel_read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file if it&#39;s an excel file

        This is the basic default reading method for 
        regular excel files.
        &#34;&#34;&#34;
        df = None
        sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)
        # header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm  = True)
        try: 
            df = pd.read_excel(
                                self._src, 
                                sheet_name = sheet_name, 
                                header = self._header, 
                                # names = raw_col_names
                            )
        except: 
            aw.HardWarning(&#34;Reader:cannot_read_csv&#34;, file = self._src)


        # try to get a FileID, from the kwargs
        # if that fails, try to get the one from fileID
        id = aux.from_kwargs(&#34;id&#34;, None, kwargs, rm = True)
        if id is not None:
            self.id_reset()
            self.id(id)
        elif isinstance(self._src, str):
            self.id_reset()
            self.id(aux.fileID(self._src))

        # vet and crop the dataframe where necessary
        df = self._vet_single_assay_df(kwargs, df)

        self._df = df

    def _vet_single_assay_df(self, kwargs, df):
        &#34;&#34;&#34;
        Vets that both Id and Ct columns are present in the data 
        and if so crops the df to the relevant columns, or checks if 
        only two columns are present anyway and then assumes Id+Ct as these two.
        &#34;&#34;&#34;
        
        # check if we got exactly two columns only
        if len( df.columns ) == 2:

            # just get the current column names for later renaming
            Id, Ct = df.columns

        else: 

            # check if a valid Ct column was found
            Ct = aux.from_kwargs( &#34;ct_label&#34;, default_ct_header, kwargs )
            Id = aux.from_kwargs( &#34;id_label&#34;, default_id_header, kwargs )
            
            valid_data = Ct in df.columns and Id in df.columns
            if not valid_data:
                aw.HardWarning(&#34;Reader:cannot_find_datacols&#34;, id_label = Id, ct_label = Ct)
            else:
                # get only the relevant data columns 
                df = df[[Id, Ct]]

        # make sure to convert Ct values to float
        tmp_parser = Parsers.CsvParser()
        Ct_col = df[Ct].to_numpy()
        df[Ct] = tmp_parser._convert_to_numeric(self.id(), Ct_col)

        # rename to qpcr default headers (id + Ct)
        df = df.rename( columns = { Id : raw_col_names[0] , Ct : raw_col_names[1] }  )
        return df

    def _filesuffix(self):
        &#34;&#34;&#34;
        Returns the file-suffix of the provided file
        &#34;&#34;&#34;
        try: 
            suffix = self._src.split(&#34;.&#34;)[-1]
            return suffix
        except: 
            pass

    def _make_new_Assay(self, name, df):
        &#34;&#34;&#34;
        Makes a new Assay object and performs group() already...
        &#34;&#34;&#34;
        new_assay = qpcr.Assay(
                                df = df, 
                                id = name, 
                                replicates = self._replicates,
                                group_names = self._names
                            )
        return new_assay

class SingleReader(_CORE_Reader):
    &#34;&#34;&#34;
    Reads qpcr raw data files in csv or excel format to get a single dataset. 

    Input Data Files
    ----------------
    Valid input files are either regular `csv` or `excel` files, or  irregular `csv` or `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Irregular input files may specify multiple assays as separate tables, 
    one assay has to be selected using the `assay` argument. 
    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`).

    #### Example of a &#34;regular&#34; single-assay datafile
    |id|Ct| other data |
    |---|---| --- |
    | ctrl1| 5.67 | ... |
    | ctrl2| 5.79 | ... |
    | ctrl3 | 5.86 | ... |
    | condA1 | 5.34 | ... |
    | ... | ... | ... |


    #### Example of an &#34;irregular&#34; single-assay datafile
    |                     |                    |            |      |      |
    | ------------------- | ------------------ | ---------- | ---- | ---- |
    | Some meta-data here | maybe today&#39;s date |            |      |      |
    |                     |                    |            |      |      |
    | Assay 1             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 5.67               | ...        |      |      |
    | ctrl2               | 5.79               | ...        |      |      |
    | ...                 | ...                |            |      |      |


    Note
    ----
    This is the successor of the original `qpcr.Reader` (not the `qpcr.SampleReader`!).
    Hence, the `SingleReader` will return a pandas DataFrame of the dataset 
    directly using `get` but not an `qpcr.Assay`. 
    An `qpcr.Assay` object will be returned after calling `make_Assay`, however. 
    Furthermore, if the provided file cannot be read as a &#34;regular&#34; file the Reader will automatically
    switch to parsing. However, if your file _is_ a regular input file, you can force regular reading 
    by passing the argument `is_regular = True` to the `read` method, which will prevent parsing and allow 
    you to figure out why regular reading may have failed instead (the Reader will not 
    provide further insight into why regular reading failed if it switches to parsing).

    Parameters
    ----------
    filename : str
        A filepath to a raw data file.
        If the file is a `csv` file, it has to have two named columns; one for replicate names, one for Ct values. 
        Both csv (`,` spearated) and csv2 (`;` separated) are accepted.
        If the file is an `excel` file it the relevant sections of the spreadsheet are identified automatically. 
        But they require identifying headers. By default it is assumed that replicate identifiers and Ct values are
        stored in columns named `Name` and `Ct` but these can be changed using 
        the `id_label` and `ct_label` arguments that can be passed as kwargs. 
        Also the assay&#39;s `id` can be set as a kwarg. 

    **kwargs
        Any additional keyword arguments that shall be passed to the `read()` method which is immediately called during init.
    &#34;&#34;&#34;
    def __init__(self, filename:str = None, **kwargs) -&gt; pd.DataFrame: 
        super().__init__()
        self._src = filename
        self._delimiter = None
        self._header = 0
        if self._src is not None:
            self.read(**kwargs)

    def read(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file.

        Note
        -----
        If the data file is an Excel file replicates and their Ct values will be 
        extracted from the first excel sheet of the file by default. 
        A separate sheet can be specified using `sheet_name`.

        Parameters
        ----------
        filename : str
            A filepath to a raw data file.
            If the file is a `csv` file, it has to have two named columns; one for replicate names, one for Ct values. 
            Both csv (`,` spearated) and csv2 (`;` separated) are accepted.
            If the file is an `excel` file it the relevant sections of the spreadsheet are identified automatically. 
            But they require identifying headers. 
            By default it is assumed that replicate identifiers and Ct values are
            stored in columns named `Name` and `Ct` but these can be changed using 
            the `id_label` and `ct_label` arguments that can be passed as kwargs. 
            Note, if only two columns are present anyway, they are assumed to be Id (1st) and Ct (2nd) column, 
            and inputs for `id_label` and `ct_label` are being ignored!
            The assay&#39;s `id` can be set as a kwarg. By default the filename is adopted as id.  
        &#34;&#34;&#34;
        self._src = filename

        self._replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        self._names = aux.from_kwargs(&#34;names&#34;, None, kwargs)
        self._header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm = True)

        if self._filesuffix() == &#34;csv&#34;:
            self._delimiter = &#34;;&#34; if self._is_csv2() else &#34;,&#34;
        super().read(**kwargs)

    def pipe(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assay

        Returns
        -------
        assay : qpcr.Assay
            An `qpcr.Assay` object of the extracted data
        &#34;&#34;&#34;
        self.read(filename = filename, **kwargs)
        assay = self.get()
        assay = self.make_Assay()
        return assay

    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        data = self.pipe(**kwargs)
        return data

    def _is_csv2(self):
        &#34;&#34;&#34;
        Tests if csv file is ; delimited (True) or common , (False)
        &#34;&#34;&#34;
        with open(self._src, &#34;r&#34;) as openfile: 
            content = openfile.read()
        if &#34;;&#34; in content: 
            return True
        return False

    def _has_header(self):
        &#34;&#34;&#34;
        Checks if column headers are provided in the data file
        It does so by checking if the second element in the first row is numeric
        if it is numeric (returns None &lt;&lt; False) no headers are presumed. Otherwise
        it returns 0 (as in first row has headers)...
        &#34;&#34;&#34;
        with open(self._src, &#34;r&#34;) as openfile: 
            content = openfile.read().split(&#34;\n&#34;)[0]
            content = content.split(self._delimiter)
        try: 
            second_col = content[1]
            second_col = float(second_col)
        except ValueError:
            return 0 # Headers in row 0
        return None  # no headers



# removed qpcr.Assay from inheritance here...
class MultiReader(SingleReader, aux._ID):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    Input Data Files
    ----------------
    Valid input files are multi-assay irregular `csv` or `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`), but ALL in the SAME sheet!

    Assays of interest and normaliser assays *must* be marked using `decorators`.

    #### Example of an &#34;irregular&#34; multi-assay datafile
    |                     |                    |            |      |      |
    | ------------------- | ------------------ | ---------- | ---- | ---- |
    | Some meta-data here | maybe today&#39;s date |            |      |      |
    |                     |                    |            |      |      |
    | Assay 1             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 5.67               | ...        |      |      |
    | ctrl2               | 5.79               | ...        |      |      |
    | ...                 | ...                |            |      |      |
    |                     |                    |            |   &lt;- blank line here!   |      |
    | Assay 2             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 10.23              | ...        |      |      |
    | ctrl2               | 10.54              | ...        |      |      |
    | ...                 | ...                |            |      |      |

    Note
    ------
    `MultiReader` can transform the extracted datasets directly into `qpcr.Assay` objects using `MultiReader.make_Assays()`.
    It will perform grouping of assays if possible but will return raw-assays if not! `get` will either return a dictionary
    of the raw dataframes or a list of `qpcr.Assay`s.

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
            Any additional keyword arguments that should be passed to the `read` method which is immediately called during init if a filename is provided.
    &#34;&#34;&#34;
    def __init__(self, filename : str = None, **kwargs):
        super(aux._ID, self).__init__()
        self._src = filename
        self._save_loc = None
        self._replicates = None
        self._names = None
        self._Parser = None
        self._assay_pattern = None
        self._assays = {}
        self._normalisers = {}
        if self._src is not None: 
            self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()
            self.read(filename = self._src, **kwargs)

    def clear(self):
        &#34;&#34;&#34;
        Clears all the extracted data from the Reader
        &#34;&#34;&#34;
        self._assays = {}
        self._normalisers = {}

    def assays(self, which : str = None):
        &#34;&#34;&#34;
        Parameters
        ----
        which : str
            If specified it only returns the data for the specified assay.
            Otherwise (default) it returns all assays.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        names : list
            A list of the names of all extracted assays.
        &#34;&#34;&#34;
        return self._get_from_which(self._assays, which)

    def normalisers(self, which : str = None):
        &#34;&#34;&#34;
        Parameters
        ----
        which : str
            If specified it only returns the data for the specified normaliser.
            Otherwise (default) it returns all normalisers.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        names : list
            A list of the names of all extracted normalisers.
        &#34;&#34;&#34;
        return self._get_from_which(self._normalisers, which)

    def get(self, which : str):
        &#34;&#34;&#34;
        Returns the stored assays or normalisers.

        Parameters
        ----------
        which : str
            Can be either `&#34;assays&#34;` or `&#34;normalisers&#34;` or any specific assay identifier.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        data = None
        if which == &#34;assays&#34;:
            data = self._assays
        elif which == &#34;normalisers&#34;:
            data = self._normalisers
        else: 
            try:
                data = self._get_from_which(self._assays, which)
            except: 
                data = self._get_from_which(self._normalisers, which)
        return data

    def read(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads a multi-assay datafile with decorated assays. 
        Any non-decorated assays are ignored!

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        **kwargs
                Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
        &#34;&#34;&#34;
        self._src = filename

        # check for a valid input file
        if self._filesuffix() not in supported_filetypes:
            aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

        self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

        # check if file should be read transposed
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            self._Parser.transpose()
        
        # setup a saving location if it was provided
        if self.save_to() is not None: 
            self._Parser.save_to(self.save_to())

        self._Parser.read(self._src, **kwargs)

    def parse(self, **kwargs):
        &#34;&#34;&#34;
        Extracts the datasets (assays) from the read datafile.
        
        Parameters
        ----------
        **kwargs
            Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `parse` method that extracts the datasets.
        &#34;&#34;&#34;
        # check for the two required inputs (either decorator must be specified or assay_pattern)
        # if neither is specified we default to using decorators!  
        decorator = aux.from_kwargs(&#34;decorator&#34;, None, kwargs)
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, None, kwargs)

        # pass kwargs to Parser for setup
        self._prep_parser(kwargs)

        # set up parsing
        if decorator is not None or assay_pattern is None:
            self._parse_by_decorators(**kwargs)
        elif assay_pattern is not None: 
            self._parse_by_pattern(kwargs, assay_pattern)
        else: 
            # ERROR HERE
            aw.SoftWarning(&#34;MultiReader:no_decorator_or_pattern&#34;)
             
    def make_Assays(self):
        &#34;&#34;&#34;
        Convert all found assays and normalisers into `qpcr.Assay` objects.
        &#34;&#34;&#34;
        # convert assays to qpcr.Assay and overwrite current dict by new list
        new_assays = []
        for name, df in self._assays.items():
            new_assay = self._make_new_Assay(name, df)
            new_assays.append(new_assay)
        self._assays = new_assays

        # do the same for normalisers
        new_normalisers = []
        for name, df in self._normalisers.items():
            new_assay = self._make_new_Assay(name, df)
            new_normalisers.append(new_assay)
        self._normalisers = new_normalisers

    def pipe(self, filename :str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assays

        Note 
        ----
        This is the suggested use of `MultiReader`. 
        If a directory has been specified into which the datafiles shall be saved, 
        then saving will automatically be done.

        Parameters
        -------
        filename : str
            A filepath to an input datafile.
        **kwargs
            Any additional keyword argument that will be passed to any of the wrapped methods.
        Returns
        -------
        data : tuple
            A tuple of the found assays-of-interst (first element) and normaliser-assays (second element).
        &#34;&#34;&#34;
        
        # clear previously read data 
        self.clear()

        # read new data
        try: 
            self.read(filename, **kwargs)
        except: 
            self.read(filename)
            aw.SoftWarning(&#34;Parser:incompatible_read_kwargs&#34;, func = f&#34;{type(self._Parser).__name__}&#39;s read method&#34;)
        
        # parse and make assays
        self.parse(**kwargs)
        self.make_Assays()

        # return new data
        assays = self.get( which = &#34;assays&#34; )
        normalisers = self.get( which = &#34;normalisers&#34; )
        return assays, normalisers

    def save_to(self, location : str = None):
        &#34;&#34;&#34;
        Sets the location into which the individual assay datafiles should be saved.
        Parameters
        ----------
        location : str
            The path to a directory where the newly generated assay datafiles shall be saved.
            If this directory does not yet exist, it will be automatically made.
        &#34;&#34;&#34;
        if location is not None: 
            self._save_loc = location
            if not os.path.exists(self._save_loc):
                os.mkdir(self._save_loc)
        return self._save_loc

    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs, rm = True)
        self.replicates(replicates)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        self.names(names)
        data = self.pipe(**kwargs)
        return data


    def _get_from_which(self, dataset, which):
        &#34;&#34;&#34;
        The core for assayS() and normalisers() to get either all or a specific one
        &#34;&#34;&#34;
        if which is not None: 
            if aux.same_type(dataset, {}):
                assay = dataset[which]
            else: 
                assay = [i for i in dataset if i.id() == which][0]
            return assay
        else:
            if aux.same_type(dataset, {}):
                names = dataset.keys()
                assays = dataset.values()
            else:
                names = [i.id() for i in dataset]
                assays = dataset
            return assays, names

    def _parse_by_pattern(self, kwargs, assay_pattern):
        &#34;&#34;&#34;
        Parses the file only based on assay_pattern.
        Note this will also work if a decorator has been specified additionally.
        &#34;&#34;&#34;
        self._Parser.parse( assay_pattern = assay_pattern, **kwargs )
        assays = self._Parser.get()       
        self._assays = assays

    def _parse_by_decorators(self, **kwargs):
        &#34;&#34;&#34;
        Parses the file and idenifies assays and normalisers
        based on decorators
        &#34;&#34;&#34;
        aux.from_kwargs(&#34;decorator&#34;, None, kwargs, rm = True)
        
        # get assays-of-interest
        self._Parser.parse( decorator = &#34;qpcr:assay&#34;, **kwargs )
        assays = self._Parser.get()       
        self._assays = assays

        # save extracted files if so desired...
        if self.save_to() is not None: self._Parser.save()

        # clear results and run again for normalisers
        self._Parser.clear()

        # get normaliser-assays
        self._Parser.parse( decorator = &#34;qpcr:normaliser&#34;, **kwargs )
        normalisers = self._Parser.get()
        self._normalisers = normalisers
        if self.save_to() is not None: self._Parser.save()

    def _prep_parser(self, kwargs):
        &#34;&#34;&#34;
        Passes kwargs to Parser and performs additional setup
        &#34;&#34;&#34;
        # setup assay_patterns if they were provided
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, None, kwargs, rm = True)
        self._Parser.assay_pattern(assay_pattern)

        # check if file should be read transposed
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            self._Parser.transpose()

        # get data column labels
        id_label = aux.from_kwargs(&#34;id_label&#34;, &#34;Name&#34;, kwargs, rm = True)
        ct_label = aux.from_kwargs(&#34;ct_label&#34;, &#34;Ct&#34;, kwargs, rm = True)
        self._Parser.labels(id_label,ct_label)

class MultiSheetReader(MultiReader):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    Input Data Files
    ----------------
    Valid input files are multi-assay irregular `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`), but may be in DIFFERENT sheets.
    All assays from all sheets will be read!

    Assays of interest and normaliser assays *must* be marked using `decorators`.


    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()

    def read(self, *args, **kwargs):
        &#34;&#34;&#34;
        The `MultiSheetReader` **only** offers a `pipe` method!
        Hence, neither `read` nor `parse` will work directly!
        &#34;&#34;&#34;
        print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)

    def parse(self, *args, **kwargs):
        &#34;&#34;&#34;
        The `MultiSheetReader` **only** offers a `pipe` method!
        Hence, neither `read` nor `parse` will work directly!
        &#34;&#34;&#34;
        print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)



    def pipe(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads a multi-assay and multi-sheet datafile with decorated assays. 
        Any non-decorated assays are ignored!

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        **kwargs
                Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
        
        Returns
        -------
        assays : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        normalisers : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        self._src = filename

        # read file to get all sheets
        sheets = pd.read_excel(filename, sheet_name = None)

        all_assays = {}
        all_normalisers = {}
        
        # now repetitively read all sheets and extract data
        reader = MultiReader()
        for sheet in sheets.keys():
            try: 
                # read file and parse data
                kws = deepcopy(kwargs)
                reader.read(filename, sheet_name = sheet)
                reader.parse(ignore_empty = True, **kws)

                # get assays
                assays, normalisers = reader.get(&#34;assays&#34;), reader.get(&#34;normalisers&#34;)
                all_assays.update(assays)
                all_normalisers.update(normalisers)

            except Exception as e: 
                # ERROR HERE
                aw.SoftWarning(&#34;MultiSheetReader:sheet_unreadable&#34;, sheet = sheets, e = e)

        # store data
        self._assays = all_assays
        self._normalisers = all_normalisers

        # try making Assays directly, return dictioanries if not possible...
        try: 
            self.make_Assays()
        except Exception as e:
            print(e)

        assays, normalisers = self._assays, self._normalisers
        return assays, normalisers
        
    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs, rm = True)
        self.replicates(replicates)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        self.names(names)
        data = self.pipe(**kwargs)
        return data

class BigTableReader(MultiReader):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    ### Input Data Files
    ----------------
    Valid input files are multi-assay irregular `csv` or `excel` files, 
    that specify assays as one big table containing all information together.
    Note that this implies that the entire data is stored in a single sheet (if using `excel` files).

    Two possible data architectures are allowed:
    
    #### `Vertical` Big Tables
    Big Tables of this kind require three columns (any additional columns are disregarded): 
    one specifying the assay, one specifying the replicate identifiers, and one specifying the Ct values. 
    An additional fourth column (`@qpcr`) may be filled with decorators but this is not necessary in this setup.

    Example:

    | assay | id   | Ct    | @qpcr |
    | ----- | ---- | ----- | ---- |
    | assay 1   | group0 | 7.65  | normaliser | 
    | assay 1   | group0 | 7.74  | normaliser | 
    | assay 1   | group0 | 7.54  | normaliser | 
    | assay 1   | group1   | 7.86  | normaliser | 
    | assay 1   | group1   | 7.57  | normaliser | 
    | assay 1   | group1   | 7.67  | normaliser | 
    | assay 2 | group0 | 16.67 | assay | 
    | assay 2 | group0 | 16.54  | assay | 
    | ...   | ...  | ...   | ... | 


    #### `Horizontal` Big Tables
    Big Tables of this kind store replicates from assays in side-by-side columns.
    The replicates may be labelled numerically or all have the same column header. 
    A second column is required specifying the replicate identifier. 

    Note, this kind of setup *requires* decorators above the first replicate of each assay,
    as well as user-defined `replicates`!

    Example:

    |      | @qpcr:group |      |      | @qpcr:group |      |      |    |
    | ---- | ---------------- | ---- | ---- | ---------------- | ---- | ---- | ---- |
    | assay   | group0_1  | group0_2  | group0_3  | group1_1 | group1_2 | ...  | @qpcr   |
    | assay1 | 7.74 | 7.65 | 7.54 | 11.54 | 11.67 | ...  |  normaliser  |
    | assay 2   | 16.67 | 16.54 | 16.97 |  16.43 |  16.56 | ...  | assay   |
    | ...  | ...  | ...  | ...  | …     | ...   | ...  |  ...  |

    &gt; Note
    &gt;
    &gt; The column headers have to be **unique** to the table!
    &gt;
    &gt; Also, a word of warning with regard to replicate _assays_. The entries in the `assay` defining column *must* be unique! If you have multiple assays from the same gene which therefore also have the same id they will be interpreted as belonging together and will be assembled into the same `qpcr.Assay` object. However, this will result in differently sized `Assays` which will cause problems downstream when you (or a `qpcr.Normaliser`) try to assemble a `qpcr.Results` object!

    #### `Hybrid` Big Tables
    Big Tables of this kind store Ct values of different assays in separate side-by-side columns, 
    but they store the replicate identifiers as a separate column. Hence, they combine aspects of vertical and horizontal Big Tables.
    

    Example: 

    |      | @qpcr:assay| @qpcr:normaliser |  |
    | ------ | ------- | ------- | ----- |
    | id     | assay 1 | assay 2 | other_data |
    | group0 | 7.65    | 11.78   |     ...  |
    | group0 | 7.87    | 11.56   |  ...     |
    | group0 | 7.89    | 11.76   |   ...    |
    | group1 | 7.56    | 11.98   |  ...     |
    | group1 | 7.34    | 11.56   |   ...    |
    | ...    | ...     | ...     |  ...     |


    &gt; Note
    &gt;
    &gt; Two options exist to read this kind of setup. 
    &gt; - A `list` of `ct_col` values can be passed which contains the column header of each assay.
    &gt; - The table can be `decorated`, in which case only decorated assays (columns) are extracted.
    &gt;
    &gt; Please, note that the two methods of reading this table are mutually exclusive! So,
    &gt; if you decorate your table you cannot pass specific assay headers to the `ct_col` argument anymore.
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()

        self._assays = {}
        self._normalisers = {}

        self._data = None

        self._Parser = None
        self._kind = None  # horizontal or vertical 
        self._id_col = None
        self._ct_col = None
        self._assay_col = None
        self._is_regular = False    # store if the datafile was regular and does not 
                                    # have to be converted to a dataframe based on a numpy array...
        self._hybrid_decorated = False  # because hybrid bigtables require decorator input separately for both read and parse, we store the info so it only needs to be passed during read...
    
    def pipe(self, filename : str, kind : str, id_col : str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assays

        Note 
        -------
        This is the suggested use of the `BigTableReader`.

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        kind : str
            Specifies the kind of Big Table from the file. 
            This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
        id_col : str
            The column header specifying the replicate identifiers 
            (or &#34;assays&#34; in case of `horizontal` big tables).
        **kwargs
            Any additional columns or keyword arguments.
        Returns
        -------
        assays : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        normalisers : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)

        self.read(
                    filename = filename, 
                    kind = kind, 
                    id_col = id_col,
                    **kwargs
                )
        self.parse(**kwargs)

        self.replicates(replicates)
        self.names(names)
        self.make_Assays()

        assays, normalisers = self.get(&#34;assays&#34;), self.get(&#34;normalisers&#34;)
        return assays, normalisers


    def read(self, filename : str, kind : str, id_col : str, **kwargs):
        &#34;&#34;&#34;
        Reads a regular or irregular `csv` or `excel` datafile that contains data stored 
        in a single big table. Files are first tried to be read regularly, if this fails, 
        the Reader resorts to parsing to identify the relevant sections of the data. 

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        kind : str
            Specifies the kind of Big Table from the file. 
            This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
        id_col : str
            The column header specifying the replicate identifiers 
            (or &#34;assays&#34; in case of `horizontal` big tables).
        **kwargs
            Any additional columns or keyword arguments.
        &#34;&#34;&#34;
        self._src = filename
        self._kind = kind
        is_horizontal = self._kind == &#34;horizontal&#34;
        self._id_col = id_col
        self._ct_col = aux.from_kwargs(&#34;ct_col&#34;, None, kwargs, rm = True)
        self._assay_col = aux.from_kwargs(&#34;assay_col&#34;, None, kwargs, rm = True)

        if not is_horizontal:
            # first try default pd.read_csv or read_excel
            self._try_simple_read(**kwargs)

            # check if we got data, and abort if so
            if self._data is not None: 
                self._df = self._data
                self._is_regular = True
                return

        # if haven&#39;t got data, then we go to parsing...

        # set is_horizontal to True for hybrid 
        # tables that are decorated
        if self._kind == &#34;hybrid&#34; and aux.from_kwargs(&#34;decorator&#34;, False, kwargs):
            is_horizontal = True
            self._hybrid_decorated = True

        # setup Parser to get data
        self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

        self._Parser.read(self._src, **kwargs)
        self._Parser.labels(id_label = self._id_col)
        self._Parser._make_BigTable_range(is_horizontal = is_horizontal)
        self._data = self._Parser._bigtable_range

    def parse(self, **kwargs):
        &#34;&#34;&#34;
        Parses the big table and extracts the individual assays.
        &#34;&#34;&#34;
        
        if self._kind == &#34;vertical&#34;:
            self._parse_vertical(**kwargs)
        elif self._kind == &#34;horizontal&#34;: 
            self._parse_horizontal(**kwargs)
        elif self._kind == &#34;hybrid&#34;:
            decorator = aux.from_kwargs(&#34;decorator&#34;, self._hybrid_decorated, kwargs, rm = True)
            self._parse_hybrid(decorator = decorator, **kwargs)
    
    def _parse_hybrid(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for hybrid big tables,
        it gets first the id_col and then all ct_cols, 
        and assembles new dfs of them into a dict
        &#34;&#34;&#34;
        # first check the kind of data we got because it 
        # can either be a pandas dataframe or a numpy ndarray
        # depending on whether or not the file is regular and/or decorated

        # it&#39;s a dataframe if it&#39;s a &#34;regular&#34; big table
        if isinstance(self._data, pd.DataFrame):

            # check if we got ct cols to extract
            if self._ct_col is None: 
                aw.HardWarning(&#34;BigTableReader:no_ct_cols&#34;, traceback = False)

            # we got a nice dataframe with columns in to extract directly
            data = self._extract_from_hybrid_dataframe(  data = self._data, to_extract = self._ct_col  )
            
            # since in this setting the data was not decorated, 
            # we store all datasets into the assays
            self._assays = data

        # it&#39;s a numpy ndarray if it&#39;s an &#34;irregular&#34; big table
        else: 
            # check if the file is supposed to be decorated
            decorator = aux.from_kwargs(&#34;decorator&#34;, False, kwargs)
            if decorator: 

                # in case it is decorated we extract 
                # data based on the decorators
                self._hybrid_bigtable_extract_by_decorator()
            
            # if we dont have decorated data, we must have received a list for 
            # ct_col values to use. So we can just transform the np.ndarray to a datafram
            # and use the same approach as for &#34;regular&#34; big tables...
            else: 
                
                # check if we got ct cols to extract
                if self._ct_col is None: 
                    aw.HardWarning(&#34;BigTableReader:no_ct_cols&#34;, traceback = False)

                # transform the numpy array from the 
                # hybrid bigtable to a pandas dataframe
                data = self._convert_hybrid_nparray_to_dataframe()

                # we got a nice dataframe with columns in to extract directly
                data = self._extract_from_hybrid_dataframe(  data = data, to_extract = self._ct_col  )
                
                # since in this setting the data was not decorated, 
                # we store all datasets into the assays
                self._assays = data

    def _convert_hybrid_nparray_to_dataframe(self):
        &#34;&#34;&#34;
        Converts a numpy array of a hybrid bigtable 
        generated by one of the Parsers into a 
        pandas DataFrame. It returns the DataFrame
        &#34;&#34;&#34;
        # first get the row in which the id_col header is located
        # this should be the second row because if it was the first, 
        # then we would have gotten a &#34;regular&#34; table anyway, so there
        # must actually be some decorators present, but the user decided
        # to ignore them. But to be save, we specifically search again. 
        starting_index = np.argwhere( self._data == self._id_col )

        # and get the row index. We assume there is only one hit for the 
        # id_col since if it were otherwise, the Parsers would have noticed
        starting_index = starting_index.reshape(starting_index.size)
        starting_index = starting_index[0]

        # and now we can assemble the data for the dataframe
        names = self._data[ starting_index, : ]
        data = self._data[ (starting_index + 1):, : ]
        data = pd.DataFrame( data, columns = names )

        return data


    def _generate_subset_dataframe(self, data, decorator):
        &#34;&#34;&#34;
        Generates a pandas DataFrame of a subset of columns 
        from a decorated hybrid big table. 

        Note
        ----
        This is a downsized version of the `qpcr.Parsers` `find_assays` core.

        Parameters
        -------
        data : np.ndarray
            A numpy array to search in. The **first** row will be searched. 
        &#34;&#34;&#34;
        
        # compile decorator to search for 
        decorator = Parsers.decorators[ decorator ]
        decorator = re.compile( decorator )

        # get first row of the data
        array = data[ 0, : ]

        # set up an index array for the columns that match
        indices = np.zeros(len(array))

        # iterate over all entries in the first row
        idx = 0 
        for entry in array:
        # try: 
            match = decorator.search(entry)
            if match is not None: 
                indices[idx] = 1
        # except: 
        #     continue
            idx += 1

        # get matching indices and reduce dimensionality
        indices = np.argwhere(indices == 1)
        indices = indices.reshape(indices.size)
            
        # now also add the id_col column to the set of relevant indices
        # for this we search in the second row, but with exact matching.
        array = data[ 1, : ]
        id_col = np.argwhere( array == self._id_col )
        id_col = id_col.reshape(id_col.size)

        # and merge the id_col to the found indices
        indices = np.concatenate( (id_col, indices) )
        

        # now get the datframe relevant subset and convert into a DataFrame
        # we get all rows except the first (since there are the decorators)
        # and only the columns with matching indices.
        names = data[ 1, indices ]
        df = data[ 2:, indices ]

        # convert to numeric
        # we use the _convert_to_numeric method from the Parsers to do that
        # we iterate over each column (except the first where the identifiers are stored)
        # and convert all entries to numeric...
        tmp_parser = Parsers.CsvParser()
        for i in range( 1, df.shape[1] ):
            df[ :, i ] = tmp_parser._convert_to_numeric( &#34;None (from BigTableReader)&#34;, df[ :, i ] )

        # convert to dataframe
        df = pd.DataFrame( df, columns = names )
        return df

    def _extract_from_hybrid_dataframe(self, data, to_extract):
        &#34;&#34;&#34;
        Extracts datasets from a hybrid dataframe 

        Parameters
        ----------
        data : pd.DataFrame
            The dataframe to extract from. This needs to include both the id_col and all ct_cols.
        to_extract : str or list
            The column names to of Ct columns extract (the id_col is referenced from self._id_col )

        Returns 
        -------
        dfs : dict
            A dictionary of all extracted assays (assay id as key, df as value).
        &#34;&#34;&#34;

        # check which columns we should extract
        # and convert to list if we only have a single one
        # just so we can use a loop uniformly
        if not isinstance(to_extract, (list,tuple)):
            to_extract = [to_extract]


        # get the id_column
        id_col = data[ self._id_col ]
        # and convert to string (just to be sure)
        id_col = id_col.astype(str)

         # setup a dict for the assay dataframes
        dfs = {}

        # iterate over all assays to extract
        for col in to_extract:
            # get ct values                
            ct_col = data[ col ]
            
            # convert to float (i.e. introduce nan were necessary)
            # to that end we use the same approach as the Parsers .make_dataframes()
            try: 
                ct_col = ct_col.astype(float)
            except: 

                ct_col = np.array( ct_col, dtype=str )
                try: 
                    ct_col = np.genfromtxt(  ct_col  )
                except: 
                    faulties = np.argwhere(    [  Parsers.float_pattern.match(i) is None for i in ct_col ]  ) 
                    ct_col[ faulties ] = &#34;nan&#34;
                    ct_col = np.genfromtxt(  ct_col  )


            # and assemble new dataframe
            tmp = pd.DataFrame(
                                    {   # using qpcr default column headers
                                        raw_col_names[0] : id_col, 
                                        raw_col_names[1] : ct_col
                                    }
                                )
            # and save dataframe
            dfs[ col ] = tmp

        # and store to data
        return dfs

    def _parse_horizontal(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for a horizontal big table
        by first transforming it to a vertical one and then using 
        the vertical parse
        &#34;&#34;&#34;
        # transform data into vertical
        self._data = self._Parser._infer_BigTable_groups(**kwargs)
        
        # transform array into df 
        # and set _is_regular to True so _parse_vertical 
        # wont try to also convert to df
        self._make_vertical_range_df()
        self._is_regular = True 

        # and parse_vertical to get assays
        ct_col = raw_col_names[1]
        assay_col = default_dataset_header
        self._id_col = raw_col_names[0]
        self._parse_vertical(ct_col = ct_col, assay_col = assay_col, **kwargs)



    def _parse_vertical(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for vertical big tables
        &#34;&#34;&#34;
        
        self._ct_col = aux.from_kwargs(&#34;ct_col&#34;, None, kwargs, rm = True)
        self._assay_col = aux.from_kwargs(&#34;assay_col&#34;, None, kwargs, rm = True)

        # in case of vertical tables, check if we got ct_col and assay_col
        got_no_cols = (self._ct_col is None or self._assay_col is None)
        if self._kind == &#34;vertical&#34; and got_no_cols:
            aw.HardWarning(&#34;BigTableReader:no_cols&#34;, ct_col = self._ct_col, assay_col = self._assay_col)
            
        # convert to pandas dataframe in case 
        # the data had to be parsed
        if not self._is_regular:
            self._make_vertical_range_df()
        
        # and test if the ones we have are good
        if not self._test_cols_are_good():
            aw.HardWarning(&#34;BigTableReader:cols_no_good&#34;, ct_col = self._ct_col, assay_col = self._assay_col)


        df = self._data
        assay_col_header = self._assay_col
        ct_col_header = self._ct_col
        id_col_header = self._id_col

        # get columns to include 
        cols_to_use = [id_col_header, ct_col_header]

        # now read the separate assays and store in assays and normalisers
        if self._vertical_decorated(): 
            # cols_to_use.append(&#34;@qpcr&#34;)
            self._get_vertical_assays_decorated(
                                                    df, 
                                                    assay_col_header, 
                                                    ct_col_header, 
                                                    cols_to_use
                                                )
        else:
            self._get_vertical_assays_not_decorated(
                                                        df, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._assays
                                                    )


    def _get_vertical_assays_decorated(self, df, assay_col_header, ct_col_header, cols_to_use):
        &#34;&#34;&#34;
        Gets assays based on decorators, storing them in _assays and _normalisers
        &#34;&#34;&#34;

        # get assays 
        tmp = df.query(&#34;`@qpcr` == &#39;assay&#39;&#34;)
        self._get_vertical_assays_not_decorated(
                                                        tmp, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._assays
                                                    )

        # get normalisers
        tmp = df.query(&#34;`@qpcr` == &#39;normaliser&#39;&#34;)
        self._get_vertical_assays_not_decorated(
                                                        tmp, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._normalisers
                                                    )

    def _get_vertical_assays_not_decorated(self, df, assay_col_header, ct_col_header, cols_to_use, store_in):
        &#34;&#34;&#34;
        Gets assays without a decorator, storing them all in self._assays...
        &#34;&#34;&#34;

        # get default names for the id and ct columns
        to_defaults = { _from : _to for _from, _to in 

                            zip(
                                    [self._id_col, self._ct_col], 
                                    raw_col_names
                                )
                    }

        # iterate over all assays
        assays = set(df[assay_col_header])
        for assay in assays:
            # get the assay subset
            subset = df.query(f&#34;`{assay_col_header}` == &#39;{assay}&#39;&#34;)
            subset = subset[cols_to_use]

            # make Cts numeric
            cts = subset[ct_col_header].to_numpy()
            cts = np.genfromtxt(  np.array(cts, dtype=str)  )
            subset[ct_col_header] = cts
            
            subset = subset.reset_index(drop = True)
            # rename to defaults
            subset = subset.rename(columns = to_defaults)

            # save assay
            store_in.update({ assay : subset })

    def _vertical_decorated(self):
        &#34;&#34;&#34;
        Checks if a vertical bigtable is decorated
        &#34;&#34;&#34;
        return &#34;@qpcr&#34; in self._data.columns

    def _make_vertical_range_df(self):
        &#34;&#34;&#34;
        Converts the numpy array from the Parser 
        to a pandas dataframe in case of irregular vertical big tables.
        &#34;&#34;&#34;
        data = self._data
        headers = data[0, :]
        data = data[ 1: ,: ]
        df = pd.DataFrame(data, columns = headers)
        self._data = df

    def _test_cols_are_good(self):
        &#34;&#34;&#34;
        Tests if specified ct and assay cols are valid
        &#34;&#34;&#34;
        cols = self._data.columns
        all_good = self._ct_col in cols and self._assay_col in cols
        return all_good

    def _try_simple_read(self, **kwargs):
        &#34;&#34;&#34;
        Try default readings without parsing in case the file is a regular
        csv or excel file (only works in case of vertical big tables).
        &#34;&#34;&#34;
        if self._filesuffix() == &#34;csv&#34;:
            
            delimiter = &#34;;&#34; if self._is_csv2() else &#34;,&#34;
            data = pd.read_csv(self._src, delimiter = delimiter)
        
        else:
            
            sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)
            data = pd.read_excel(self._src, sheet_name = sheet_name)
        
        # check if we got the data we looked for...
        got_regular_data = self._id_col in data.columns
        if got_regular_data:
            self._data = data
        
    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        # replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        # self.replicates(replicates)
        # names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        # self.names(names)
        data = self.pipe(**kwargs)
        return data

    def _hybrid_bigtable_extract_by_decorator(self):
        &#34;&#34;&#34;
        Extracts assays and normalisers based 
        on decorators from a decorated hybrid big table.
        &#34;&#34;&#34;
        # find all assays first
        data = self._generate_subset_dataframe( 
                                                    data = self._data, 
                                                    decorator = &#34;qpcr:assay&#34; 
                                            )
        # now that we have a nice dataframe 
        # we can select all columns that are not the id_col as our ct_cols of interest
        # and use the same _extract_from_hybrid_dataframe as for the undecorated hybrid tables.
        ct_cols = [ i for i in data.columns if i != self._id_col ]
        data = self._extract_from_hybrid_dataframe(  data = data, to_extract = ct_cols  )

        # and save to the assays
        self._assays = data

        # now repeat the same for the normalisers
        data = self._generate_subset_dataframe( 
                                                    data = self._data, 
                                                    decorator = &#34;qpcr:normaliser&#34; 
                                            )
        ct_cols = [ i for i in data.columns if i != self._id_col ]
        data = self._extract_from_hybrid_dataframe(  data = data, to_extract = ct_cols  )

        # and save to the normalisers
        self._normalisers = data


if __name__ == &#34;__main__&#34;:

    # multisheet_file = &#34;/Users/NoahHK/Downloads/Corti IPSCs July 2019_decorated.xlsx&#34;
    # decorated_excel = &#34;./__parser_data/excel 3.9.19_decorated.xlsx&#34;

    # reader = MultiReader()
    # reader.read(decorated_excel, sheet_name = 1)
    # reader.parse(decorator = True, ignore_empty = True, assay_pattern = &#34;Rotor-Gene&#34;)
    # reader.make_Assays()
    # r = reader.get(&#34;assays&#34;)
    # print(r[0].get())
    # assert r is not None, &#34;MultiReader failed somewhere...&#34;

    # reader = MultiSheetReader()
    # reader.pipe(
    #             multisheet_file, 
    #             # decorator = True, 
    #             assay_pattern = &#34;Rotor-Gene&#34;
    #         )
    # print(reader.get(&#34;Actin&#34;))

    # bigtable_horiztonal = &#34;/Users/NoahHK/Downloads/Local_cohort_Adenoma_qPCR_rawdata_decorated.xlsx&#34;
    # bigtable_vertical = &#34;/Users/NoahHK/Downloads/qPCR all plates.xlsx&#34;

    # reader = BigTableReader()


    # reader.read(bigtable_vertical, kind = &#34;vertical&#34;, id_col = &#34;Individual&#34;)
    # reader.parse(ct_col = &#34;Ct&#34;, assay_col = &#34;Gene&#34;)
    # reader.make_Assays()
    # r = reader.get(&#34;assays&#34;)
    # print(r[0].get(), r[0].id())
    # reader.clear()


    # assays, normalisers = reader._DataReader(
    #                                     filename = bigtable_horiztonal, 
    #                                     kind = &#34;horizontal&#34;, 
    #                                     id_col = &#34;tissue_number&#34;,
    #                                     replicates = (3,4), 
    #                                     names = [&#34;Gapdh&#34;, &#34;Sord1&#34;]
    #                                 )
    # r = normalisers
    # print(r[0].get())

    # reader = qpcr.DataReader()
    # r = reader.read( &#34;./Examples/Example Data/actin.xlsx&#34;, header = 0, replicates = None, id = &#34;myActin&#34;)
    # # r = reader.make_Assay()
    # print(r.get(), r.id())


    # reader.read( &#34;./Examples/Example Data/actin_nan.csv&#34;, replicates = 6, id_label = &#34;Hii&#34;, id = &#34;myActin&#34;, is_regular = True )
    # r = reader.make_Assay()
    # print(r.get(), r.id())

    hybrid_bigtable = &#34;./Examples/Example Data/Big Table Files/hybrid_bigtable.xlsx&#34;

    # sheet 0 is not decorated 
    # sheet 1 is decorated 

    reader = BigTableReader()
    reader.read(
                    hybrid_bigtable, 
                    kind = &#34;hybrid&#34;, 
                    id_col = &#34;group&#34;, 
                    # ct_col = [&#34;TLR1&#34;, &#34;TLR4&#34;, &#34;GAPDH&#34;],
                    decorator = True, 
                    sheet_name = 1
            )
    reader.parse()
    reader.make_Assays()
    r = reader.assays()
    print(r)
    print(r[0][0].get())

    print(r[0][0].get().dtypes)
    r = reader.normalisers()
    print(r)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="qpcr.Readers.Readers.BigTableReader"><code class="flex name class">
<span>class <span class="ident">BigTableReader</span></span>
</code></dt>
<dd>
<div class="desc"><p>Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.</p>
<h3 id="input-data-files">Input Data Files</h3>
<hr>
<p>Valid input files are multi-assay irregular <code>csv</code> or <code>excel</code> files,
that specify assays as one big table containing all information together.
Note that this implies that the entire data is stored in a single sheet (if using <code>excel</code> files).</p>
<p>Two possible data architectures are allowed:</p>
<h4 id="vertical-big-tables"><code>Vertical</code> Big Tables</h4>
<p>Big Tables of this kind require three columns (any additional columns are disregarded):
one specifying the assay, one specifying the replicate identifiers, and one specifying the Ct values.
An additional fourth column (<code>@qpcr</code>) may be filled with decorators but this is not necessary in this setup.</p>
<p>Example:</p>
<table>
<thead>
<tr>
<th>assay</th>
<th>id</th>
<th>Ct</th>
<th>@qpcr</th>
</tr>
</thead>
<tbody>
<tr>
<td>assay 1</td>
<td>group0</td>
<td>7.65</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 1</td>
<td>group0</td>
<td>7.74</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 1</td>
<td>group0</td>
<td>7.54</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 1</td>
<td>group1</td>
<td>7.86</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 1</td>
<td>group1</td>
<td>7.57</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 1</td>
<td>group1</td>
<td>7.67</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 2</td>
<td>group0</td>
<td>16.67</td>
<td>assay</td>
</tr>
<tr>
<td>assay 2</td>
<td>group0</td>
<td>16.54</td>
<td>assay</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h4 id="horizontal-big-tables"><code>Horizontal</code> Big Tables</h4>
<p>Big Tables of this kind store replicates from assays in side-by-side columns.
The replicates may be labelled numerically or all have the same column header.
A second column is required specifying the replicate identifier. </p>
<p>Note, this kind of setup <em>requires</em> decorators above the first replicate of each assay,
as well as user-defined <code>replicates</code>!</p>
<p>Example:</p>
<table>
<thead>
<tr>
<th></th>
<th>@qpcr:group</th>
<th></th>
<th></th>
<th>@qpcr:group</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>assay</td>
<td>group0_1</td>
<td>group0_2</td>
<td>group0_3</td>
<td>group1_1</td>
<td>group1_2</td>
<td>&hellip;</td>
<td>@qpcr</td>
</tr>
<tr>
<td>assay1</td>
<td>7.74</td>
<td>7.65</td>
<td>7.54</td>
<td>11.54</td>
<td>11.67</td>
<td>&hellip;</td>
<td>normaliser</td>
</tr>
<tr>
<td>assay 2</td>
<td>16.67</td>
<td>16.54</td>
<td>16.97</td>
<td>16.43</td>
<td>16.56</td>
<td>&hellip;</td>
<td>assay</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>…</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Note</p>
<p>The column headers have to be <strong>unique</strong> to the table!</p>
<p>Also, a word of warning with regard to replicate <em>assays</em>. The entries in the <code>assay</code> defining column <em>must</em> be unique! If you have multiple assays from the same gene which therefore also have the same id they will be interpreted as belonging together and will be assembled into the same <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> object. However, this will result in differently sized <code>Assays</code> which will cause problems downstream when you (or a <code><a title="qpcr.Normaliser" href="../index.html#qpcr.Normaliser">Normaliser</a></code>) try to assemble a <code><a title="qpcr.Results" href="../index.html#qpcr.Results">Results</a></code> object!</p>
</blockquote>
<h4 id="hybrid-big-tables"><code>Hybrid</code> Big Tables</h4>
<p>Big Tables of this kind store Ct values of different assays in separate side-by-side columns,
but they store the replicate identifiers as a separate column. Hence, they combine aspects of vertical and horizontal Big Tables.</p>
<p>Example: </p>
<table>
<thead>
<tr>
<th></th>
<th>@qpcr:assay</th>
<th>@qpcr:normaliser</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>assay 1</td>
<td>assay 2</td>
<td>other_data</td>
</tr>
<tr>
<td>group0</td>
<td>7.65</td>
<td>11.78</td>
<td>&hellip;</td>
</tr>
<tr>
<td>group0</td>
<td>7.87</td>
<td>11.56</td>
<td>&hellip;</td>
</tr>
<tr>
<td>group0</td>
<td>7.89</td>
<td>11.76</td>
<td>&hellip;</td>
</tr>
<tr>
<td>group1</td>
<td>7.56</td>
<td>11.98</td>
<td>&hellip;</td>
</tr>
<tr>
<td>group1</td>
<td>7.34</td>
<td>11.56</td>
<td>&hellip;</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Note</p>
<p>Two options exist to read this kind of setup.
- A <code>list</code> of <code>ct_col</code> values can be passed which contains the column header of each assay.
- The table can be <code>decorated</code>, in which case only decorated assays (columns) are extracted.</p>
<p>Please, note that the two methods of reading this table are mutually exclusive! So,
if you decorate your table you cannot pass specific assay headers to the <code>ct_col</code> argument anymore.</p>
</blockquote></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BigTableReader(MultiReader):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    ### Input Data Files
    ----------------
    Valid input files are multi-assay irregular `csv` or `excel` files, 
    that specify assays as one big table containing all information together.
    Note that this implies that the entire data is stored in a single sheet (if using `excel` files).

    Two possible data architectures are allowed:
    
    #### `Vertical` Big Tables
    Big Tables of this kind require three columns (any additional columns are disregarded): 
    one specifying the assay, one specifying the replicate identifiers, and one specifying the Ct values. 
    An additional fourth column (`@qpcr`) may be filled with decorators but this is not necessary in this setup.

    Example:

    | assay | id   | Ct    | @qpcr |
    | ----- | ---- | ----- | ---- |
    | assay 1   | group0 | 7.65  | normaliser | 
    | assay 1   | group0 | 7.74  | normaliser | 
    | assay 1   | group0 | 7.54  | normaliser | 
    | assay 1   | group1   | 7.86  | normaliser | 
    | assay 1   | group1   | 7.57  | normaliser | 
    | assay 1   | group1   | 7.67  | normaliser | 
    | assay 2 | group0 | 16.67 | assay | 
    | assay 2 | group0 | 16.54  | assay | 
    | ...   | ...  | ...   | ... | 


    #### `Horizontal` Big Tables
    Big Tables of this kind store replicates from assays in side-by-side columns.
    The replicates may be labelled numerically or all have the same column header. 
    A second column is required specifying the replicate identifier. 

    Note, this kind of setup *requires* decorators above the first replicate of each assay,
    as well as user-defined `replicates`!

    Example:

    |      | @qpcr:group |      |      | @qpcr:group |      |      |    |
    | ---- | ---------------- | ---- | ---- | ---------------- | ---- | ---- | ---- |
    | assay   | group0_1  | group0_2  | group0_3  | group1_1 | group1_2 | ...  | @qpcr   |
    | assay1 | 7.74 | 7.65 | 7.54 | 11.54 | 11.67 | ...  |  normaliser  |
    | assay 2   | 16.67 | 16.54 | 16.97 |  16.43 |  16.56 | ...  | assay   |
    | ...  | ...  | ...  | ...  | …     | ...   | ...  |  ...  |

    &gt; Note
    &gt;
    &gt; The column headers have to be **unique** to the table!
    &gt;
    &gt; Also, a word of warning with regard to replicate _assays_. The entries in the `assay` defining column *must* be unique! If you have multiple assays from the same gene which therefore also have the same id they will be interpreted as belonging together and will be assembled into the same `qpcr.Assay` object. However, this will result in differently sized `Assays` which will cause problems downstream when you (or a `qpcr.Normaliser`) try to assemble a `qpcr.Results` object!

    #### `Hybrid` Big Tables
    Big Tables of this kind store Ct values of different assays in separate side-by-side columns, 
    but they store the replicate identifiers as a separate column. Hence, they combine aspects of vertical and horizontal Big Tables.
    

    Example: 

    |      | @qpcr:assay| @qpcr:normaliser |  |
    | ------ | ------- | ------- | ----- |
    | id     | assay 1 | assay 2 | other_data |
    | group0 | 7.65    | 11.78   |     ...  |
    | group0 | 7.87    | 11.56   |  ...     |
    | group0 | 7.89    | 11.76   |   ...    |
    | group1 | 7.56    | 11.98   |  ...     |
    | group1 | 7.34    | 11.56   |   ...    |
    | ...    | ...     | ...     |  ...     |


    &gt; Note
    &gt;
    &gt; Two options exist to read this kind of setup. 
    &gt; - A `list` of `ct_col` values can be passed which contains the column header of each assay.
    &gt; - The table can be `decorated`, in which case only decorated assays (columns) are extracted.
    &gt;
    &gt; Please, note that the two methods of reading this table are mutually exclusive! So,
    &gt; if you decorate your table you cannot pass specific assay headers to the `ct_col` argument anymore.
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()

        self._assays = {}
        self._normalisers = {}

        self._data = None

        self._Parser = None
        self._kind = None  # horizontal or vertical 
        self._id_col = None
        self._ct_col = None
        self._assay_col = None
        self._is_regular = False    # store if the datafile was regular and does not 
                                    # have to be converted to a dataframe based on a numpy array...
        self._hybrid_decorated = False  # because hybrid bigtables require decorator input separately for both read and parse, we store the info so it only needs to be passed during read...
    
    def pipe(self, filename : str, kind : str, id_col : str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assays

        Note 
        -------
        This is the suggested use of the `BigTableReader`.

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        kind : str
            Specifies the kind of Big Table from the file. 
            This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
        id_col : str
            The column header specifying the replicate identifiers 
            (or &#34;assays&#34; in case of `horizontal` big tables).
        **kwargs
            Any additional columns or keyword arguments.
        Returns
        -------
        assays : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        normalisers : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)

        self.read(
                    filename = filename, 
                    kind = kind, 
                    id_col = id_col,
                    **kwargs
                )
        self.parse(**kwargs)

        self.replicates(replicates)
        self.names(names)
        self.make_Assays()

        assays, normalisers = self.get(&#34;assays&#34;), self.get(&#34;normalisers&#34;)
        return assays, normalisers


    def read(self, filename : str, kind : str, id_col : str, **kwargs):
        &#34;&#34;&#34;
        Reads a regular or irregular `csv` or `excel` datafile that contains data stored 
        in a single big table. Files are first tried to be read regularly, if this fails, 
        the Reader resorts to parsing to identify the relevant sections of the data. 

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        kind : str
            Specifies the kind of Big Table from the file. 
            This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
        id_col : str
            The column header specifying the replicate identifiers 
            (or &#34;assays&#34; in case of `horizontal` big tables).
        **kwargs
            Any additional columns or keyword arguments.
        &#34;&#34;&#34;
        self._src = filename
        self._kind = kind
        is_horizontal = self._kind == &#34;horizontal&#34;
        self._id_col = id_col
        self._ct_col = aux.from_kwargs(&#34;ct_col&#34;, None, kwargs, rm = True)
        self._assay_col = aux.from_kwargs(&#34;assay_col&#34;, None, kwargs, rm = True)

        if not is_horizontal:
            # first try default pd.read_csv or read_excel
            self._try_simple_read(**kwargs)

            # check if we got data, and abort if so
            if self._data is not None: 
                self._df = self._data
                self._is_regular = True
                return

        # if haven&#39;t got data, then we go to parsing...

        # set is_horizontal to True for hybrid 
        # tables that are decorated
        if self._kind == &#34;hybrid&#34; and aux.from_kwargs(&#34;decorator&#34;, False, kwargs):
            is_horizontal = True
            self._hybrid_decorated = True

        # setup Parser to get data
        self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

        self._Parser.read(self._src, **kwargs)
        self._Parser.labels(id_label = self._id_col)
        self._Parser._make_BigTable_range(is_horizontal = is_horizontal)
        self._data = self._Parser._bigtable_range

    def parse(self, **kwargs):
        &#34;&#34;&#34;
        Parses the big table and extracts the individual assays.
        &#34;&#34;&#34;
        
        if self._kind == &#34;vertical&#34;:
            self._parse_vertical(**kwargs)
        elif self._kind == &#34;horizontal&#34;: 
            self._parse_horizontal(**kwargs)
        elif self._kind == &#34;hybrid&#34;:
            decorator = aux.from_kwargs(&#34;decorator&#34;, self._hybrid_decorated, kwargs, rm = True)
            self._parse_hybrid(decorator = decorator, **kwargs)
    
    def _parse_hybrid(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for hybrid big tables,
        it gets first the id_col and then all ct_cols, 
        and assembles new dfs of them into a dict
        &#34;&#34;&#34;
        # first check the kind of data we got because it 
        # can either be a pandas dataframe or a numpy ndarray
        # depending on whether or not the file is regular and/or decorated

        # it&#39;s a dataframe if it&#39;s a &#34;regular&#34; big table
        if isinstance(self._data, pd.DataFrame):

            # check if we got ct cols to extract
            if self._ct_col is None: 
                aw.HardWarning(&#34;BigTableReader:no_ct_cols&#34;, traceback = False)

            # we got a nice dataframe with columns in to extract directly
            data = self._extract_from_hybrid_dataframe(  data = self._data, to_extract = self._ct_col  )
            
            # since in this setting the data was not decorated, 
            # we store all datasets into the assays
            self._assays = data

        # it&#39;s a numpy ndarray if it&#39;s an &#34;irregular&#34; big table
        else: 
            # check if the file is supposed to be decorated
            decorator = aux.from_kwargs(&#34;decorator&#34;, False, kwargs)
            if decorator: 

                # in case it is decorated we extract 
                # data based on the decorators
                self._hybrid_bigtable_extract_by_decorator()
            
            # if we dont have decorated data, we must have received a list for 
            # ct_col values to use. So we can just transform the np.ndarray to a datafram
            # and use the same approach as for &#34;regular&#34; big tables...
            else: 
                
                # check if we got ct cols to extract
                if self._ct_col is None: 
                    aw.HardWarning(&#34;BigTableReader:no_ct_cols&#34;, traceback = False)

                # transform the numpy array from the 
                # hybrid bigtable to a pandas dataframe
                data = self._convert_hybrid_nparray_to_dataframe()

                # we got a nice dataframe with columns in to extract directly
                data = self._extract_from_hybrid_dataframe(  data = data, to_extract = self._ct_col  )
                
                # since in this setting the data was not decorated, 
                # we store all datasets into the assays
                self._assays = data

    def _convert_hybrid_nparray_to_dataframe(self):
        &#34;&#34;&#34;
        Converts a numpy array of a hybrid bigtable 
        generated by one of the Parsers into a 
        pandas DataFrame. It returns the DataFrame
        &#34;&#34;&#34;
        # first get the row in which the id_col header is located
        # this should be the second row because if it was the first, 
        # then we would have gotten a &#34;regular&#34; table anyway, so there
        # must actually be some decorators present, but the user decided
        # to ignore them. But to be save, we specifically search again. 
        starting_index = np.argwhere( self._data == self._id_col )

        # and get the row index. We assume there is only one hit for the 
        # id_col since if it were otherwise, the Parsers would have noticed
        starting_index = starting_index.reshape(starting_index.size)
        starting_index = starting_index[0]

        # and now we can assemble the data for the dataframe
        names = self._data[ starting_index, : ]
        data = self._data[ (starting_index + 1):, : ]
        data = pd.DataFrame( data, columns = names )

        return data


    def _generate_subset_dataframe(self, data, decorator):
        &#34;&#34;&#34;
        Generates a pandas DataFrame of a subset of columns 
        from a decorated hybrid big table. 

        Note
        ----
        This is a downsized version of the `qpcr.Parsers` `find_assays` core.

        Parameters
        -------
        data : np.ndarray
            A numpy array to search in. The **first** row will be searched. 
        &#34;&#34;&#34;
        
        # compile decorator to search for 
        decorator = Parsers.decorators[ decorator ]
        decorator = re.compile( decorator )

        # get first row of the data
        array = data[ 0, : ]

        # set up an index array for the columns that match
        indices = np.zeros(len(array))

        # iterate over all entries in the first row
        idx = 0 
        for entry in array:
        # try: 
            match = decorator.search(entry)
            if match is not None: 
                indices[idx] = 1
        # except: 
        #     continue
            idx += 1

        # get matching indices and reduce dimensionality
        indices = np.argwhere(indices == 1)
        indices = indices.reshape(indices.size)
            
        # now also add the id_col column to the set of relevant indices
        # for this we search in the second row, but with exact matching.
        array = data[ 1, : ]
        id_col = np.argwhere( array == self._id_col )
        id_col = id_col.reshape(id_col.size)

        # and merge the id_col to the found indices
        indices = np.concatenate( (id_col, indices) )
        

        # now get the datframe relevant subset and convert into a DataFrame
        # we get all rows except the first (since there are the decorators)
        # and only the columns with matching indices.
        names = data[ 1, indices ]
        df = data[ 2:, indices ]

        # convert to numeric
        # we use the _convert_to_numeric method from the Parsers to do that
        # we iterate over each column (except the first where the identifiers are stored)
        # and convert all entries to numeric...
        tmp_parser = Parsers.CsvParser()
        for i in range( 1, df.shape[1] ):
            df[ :, i ] = tmp_parser._convert_to_numeric( &#34;None (from BigTableReader)&#34;, df[ :, i ] )

        # convert to dataframe
        df = pd.DataFrame( df, columns = names )
        return df

    def _extract_from_hybrid_dataframe(self, data, to_extract):
        &#34;&#34;&#34;
        Extracts datasets from a hybrid dataframe 

        Parameters
        ----------
        data : pd.DataFrame
            The dataframe to extract from. This needs to include both the id_col and all ct_cols.
        to_extract : str or list
            The column names to of Ct columns extract (the id_col is referenced from self._id_col )

        Returns 
        -------
        dfs : dict
            A dictionary of all extracted assays (assay id as key, df as value).
        &#34;&#34;&#34;

        # check which columns we should extract
        # and convert to list if we only have a single one
        # just so we can use a loop uniformly
        if not isinstance(to_extract, (list,tuple)):
            to_extract = [to_extract]


        # get the id_column
        id_col = data[ self._id_col ]
        # and convert to string (just to be sure)
        id_col = id_col.astype(str)

         # setup a dict for the assay dataframes
        dfs = {}

        # iterate over all assays to extract
        for col in to_extract:
            # get ct values                
            ct_col = data[ col ]
            
            # convert to float (i.e. introduce nan were necessary)
            # to that end we use the same approach as the Parsers .make_dataframes()
            try: 
                ct_col = ct_col.astype(float)
            except: 

                ct_col = np.array( ct_col, dtype=str )
                try: 
                    ct_col = np.genfromtxt(  ct_col  )
                except: 
                    faulties = np.argwhere(    [  Parsers.float_pattern.match(i) is None for i in ct_col ]  ) 
                    ct_col[ faulties ] = &#34;nan&#34;
                    ct_col = np.genfromtxt(  ct_col  )


            # and assemble new dataframe
            tmp = pd.DataFrame(
                                    {   # using qpcr default column headers
                                        raw_col_names[0] : id_col, 
                                        raw_col_names[1] : ct_col
                                    }
                                )
            # and save dataframe
            dfs[ col ] = tmp

        # and store to data
        return dfs

    def _parse_horizontal(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for a horizontal big table
        by first transforming it to a vertical one and then using 
        the vertical parse
        &#34;&#34;&#34;
        # transform data into vertical
        self._data = self._Parser._infer_BigTable_groups(**kwargs)
        
        # transform array into df 
        # and set _is_regular to True so _parse_vertical 
        # wont try to also convert to df
        self._make_vertical_range_df()
        self._is_regular = True 

        # and parse_vertical to get assays
        ct_col = raw_col_names[1]
        assay_col = default_dataset_header
        self._id_col = raw_col_names[0]
        self._parse_vertical(ct_col = ct_col, assay_col = assay_col, **kwargs)



    def _parse_vertical(self, **kwargs):
        &#34;&#34;&#34;
        Extracts assay datasets for vertical big tables
        &#34;&#34;&#34;
        
        self._ct_col = aux.from_kwargs(&#34;ct_col&#34;, None, kwargs, rm = True)
        self._assay_col = aux.from_kwargs(&#34;assay_col&#34;, None, kwargs, rm = True)

        # in case of vertical tables, check if we got ct_col and assay_col
        got_no_cols = (self._ct_col is None or self._assay_col is None)
        if self._kind == &#34;vertical&#34; and got_no_cols:
            aw.HardWarning(&#34;BigTableReader:no_cols&#34;, ct_col = self._ct_col, assay_col = self._assay_col)
            
        # convert to pandas dataframe in case 
        # the data had to be parsed
        if not self._is_regular:
            self._make_vertical_range_df()
        
        # and test if the ones we have are good
        if not self._test_cols_are_good():
            aw.HardWarning(&#34;BigTableReader:cols_no_good&#34;, ct_col = self._ct_col, assay_col = self._assay_col)


        df = self._data
        assay_col_header = self._assay_col
        ct_col_header = self._ct_col
        id_col_header = self._id_col

        # get columns to include 
        cols_to_use = [id_col_header, ct_col_header]

        # now read the separate assays and store in assays and normalisers
        if self._vertical_decorated(): 
            # cols_to_use.append(&#34;@qpcr&#34;)
            self._get_vertical_assays_decorated(
                                                    df, 
                                                    assay_col_header, 
                                                    ct_col_header, 
                                                    cols_to_use
                                                )
        else:
            self._get_vertical_assays_not_decorated(
                                                        df, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._assays
                                                    )


    def _get_vertical_assays_decorated(self, df, assay_col_header, ct_col_header, cols_to_use):
        &#34;&#34;&#34;
        Gets assays based on decorators, storing them in _assays and _normalisers
        &#34;&#34;&#34;

        # get assays 
        tmp = df.query(&#34;`@qpcr` == &#39;assay&#39;&#34;)
        self._get_vertical_assays_not_decorated(
                                                        tmp, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._assays
                                                    )

        # get normalisers
        tmp = df.query(&#34;`@qpcr` == &#39;normaliser&#39;&#34;)
        self._get_vertical_assays_not_decorated(
                                                        tmp, 
                                                        assay_col_header, 
                                                        ct_col_header, 
                                                        cols_to_use,
                                                        self._normalisers
                                                    )

    def _get_vertical_assays_not_decorated(self, df, assay_col_header, ct_col_header, cols_to_use, store_in):
        &#34;&#34;&#34;
        Gets assays without a decorator, storing them all in self._assays...
        &#34;&#34;&#34;

        # get default names for the id and ct columns
        to_defaults = { _from : _to for _from, _to in 

                            zip(
                                    [self._id_col, self._ct_col], 
                                    raw_col_names
                                )
                    }

        # iterate over all assays
        assays = set(df[assay_col_header])
        for assay in assays:
            # get the assay subset
            subset = df.query(f&#34;`{assay_col_header}` == &#39;{assay}&#39;&#34;)
            subset = subset[cols_to_use]

            # make Cts numeric
            cts = subset[ct_col_header].to_numpy()
            cts = np.genfromtxt(  np.array(cts, dtype=str)  )
            subset[ct_col_header] = cts
            
            subset = subset.reset_index(drop = True)
            # rename to defaults
            subset = subset.rename(columns = to_defaults)

            # save assay
            store_in.update({ assay : subset })

    def _vertical_decorated(self):
        &#34;&#34;&#34;
        Checks if a vertical bigtable is decorated
        &#34;&#34;&#34;
        return &#34;@qpcr&#34; in self._data.columns

    def _make_vertical_range_df(self):
        &#34;&#34;&#34;
        Converts the numpy array from the Parser 
        to a pandas dataframe in case of irregular vertical big tables.
        &#34;&#34;&#34;
        data = self._data
        headers = data[0, :]
        data = data[ 1: ,: ]
        df = pd.DataFrame(data, columns = headers)
        self._data = df

    def _test_cols_are_good(self):
        &#34;&#34;&#34;
        Tests if specified ct and assay cols are valid
        &#34;&#34;&#34;
        cols = self._data.columns
        all_good = self._ct_col in cols and self._assay_col in cols
        return all_good

    def _try_simple_read(self, **kwargs):
        &#34;&#34;&#34;
        Try default readings without parsing in case the file is a regular
        csv or excel file (only works in case of vertical big tables).
        &#34;&#34;&#34;
        if self._filesuffix() == &#34;csv&#34;:
            
            delimiter = &#34;;&#34; if self._is_csv2() else &#34;,&#34;
            data = pd.read_csv(self._src, delimiter = delimiter)
        
        else:
            
            sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)
            data = pd.read_excel(self._src, sheet_name = sheet_name)
        
        # check if we got the data we looked for...
        got_regular_data = self._id_col in data.columns
        if got_regular_data:
            self._data = data
        
    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        # replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        # self.replicates(replicates)
        # names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        # self.names(names)
        data = self.pipe(**kwargs)
        return data

    def _hybrid_bigtable_extract_by_decorator(self):
        &#34;&#34;&#34;
        Extracts assays and normalisers based 
        on decorators from a decorated hybrid big table.
        &#34;&#34;&#34;
        # find all assays first
        data = self._generate_subset_dataframe( 
                                                    data = self._data, 
                                                    decorator = &#34;qpcr:assay&#34; 
                                            )
        # now that we have a nice dataframe 
        # we can select all columns that are not the id_col as our ct_cols of interest
        # and use the same _extract_from_hybrid_dataframe as for the undecorated hybrid tables.
        ct_cols = [ i for i in data.columns if i != self._id_col ]
        data = self._extract_from_hybrid_dataframe(  data = data, to_extract = ct_cols  )

        # and save to the assays
        self._assays = data

        # now repeat the same for the normalisers
        data = self._generate_subset_dataframe( 
                                                    data = self._data, 
                                                    decorator = &#34;qpcr:normaliser&#34; 
                                            )
        ct_cols = [ i for i in data.columns if i != self._id_col ]
        data = self._extract_from_hybrid_dataframe(  data = data, to_extract = ct_cols  )

        # and save to the normalisers
        self._normalisers = data</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></li>
<li><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></li>
<li><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></li>
<li>qpcr._auxiliary._ID</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="qpcr.Readers.Readers.BigTableReader.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Parses the big table and extracts the individual assays.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(self, **kwargs):
    &#34;&#34;&#34;
    Parses the big table and extracts the individual assays.
    &#34;&#34;&#34;
    
    if self._kind == &#34;vertical&#34;:
        self._parse_vertical(**kwargs)
    elif self._kind == &#34;horizontal&#34;: 
        self._parse_horizontal(**kwargs)
    elif self._kind == &#34;hybrid&#34;:
        decorator = aux.from_kwargs(&#34;decorator&#34;, self._hybrid_decorated, kwargs, rm = True)
        self._parse_hybrid(decorator = decorator, **kwargs)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.BigTableReader.pipe"><code class="name flex">
<span>def <span class="ident">pipe</span></span>(<span>self, filename: str, kind: str, id_col: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A wrapper for read+parse+make_Assays</p>
<h2 id="note">Note</h2>
<p>This is the suggested use of the <code><a title="qpcr.Readers.Readers.BigTableReader" href="#qpcr.Readers.Readers.BigTableReader">BigTableReader</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>kind</code></strong> :&ensp;<code>str</code></dt>
<dd>Specifies the kind of Big Table from the file.
This may either be <code>"horizontal"</code>, <code>"vertical"</code>, or <code>"hybrid"</code>.</dd>
<dt><strong><code>id_col</code></strong> :&ensp;<code>str</code></dt>
<dd>The column header specifying the replicate identifiers
(or "assays" in case of <code>horizontal</code> big tables).</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional columns or keyword arguments.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>assays</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
<dt><strong><code>normalisers</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser
(if no qpcr.Assays could be made automatically)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipe(self, filename : str, kind : str, id_col : str, **kwargs):
    &#34;&#34;&#34;
    A wrapper for read+parse+make_Assays

    Note 
    -------
    This is the suggested use of the `BigTableReader`.

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    kind : str
        Specifies the kind of Big Table from the file. 
        This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
    id_col : str
        The column header specifying the replicate identifiers 
        (or &#34;assays&#34; in case of `horizontal` big tables).
    **kwargs
        Any additional columns or keyword arguments.
    Returns
    -------
    assays : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
        or a list of `qpcr.Assay` objects.
    normalisers : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser 
        (if no qpcr.Assays could be made automatically)
        or a list of `qpcr.Assay` objects.
    &#34;&#34;&#34;
    replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
    names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)

    self.read(
                filename = filename, 
                kind = kind, 
                id_col = id_col,
                **kwargs
            )
    self.parse(**kwargs)

    self.replicates(replicates)
    self.names(names)
    self.make_Assays()

    assays, normalisers = self.get(&#34;assays&#34;), self.get(&#34;normalisers&#34;)
    return assays, normalisers</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.BigTableReader.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, filename: str, kind: str, id_col: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a regular or irregular <code>csv</code> or <code>excel</code> datafile that contains data stored
in a single big table. Files are first tried to be read regularly, if this fails,
the Reader resorts to parsing to identify the relevant sections of the data. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>kind</code></strong> :&ensp;<code>str</code></dt>
<dd>Specifies the kind of Big Table from the file.
This may either be <code>"horizontal"</code>, <code>"vertical"</code>, or <code>"hybrid"</code>.</dd>
<dt><strong><code>id_col</code></strong> :&ensp;<code>str</code></dt>
<dd>The column header specifying the replicate identifiers
(or "assays" in case of <code>horizontal</code> big tables).</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional columns or keyword arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, filename : str, kind : str, id_col : str, **kwargs):
    &#34;&#34;&#34;
    Reads a regular or irregular `csv` or `excel` datafile that contains data stored 
    in a single big table. Files are first tried to be read regularly, if this fails, 
    the Reader resorts to parsing to identify the relevant sections of the data. 

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    kind : str
        Specifies the kind of Big Table from the file. 
        This may either be `&#34;horizontal&#34;`, `&#34;vertical&#34;`, or `&#34;hybrid&#34;`.
    id_col : str
        The column header specifying the replicate identifiers 
        (or &#34;assays&#34; in case of `horizontal` big tables).
    **kwargs
        Any additional columns or keyword arguments.
    &#34;&#34;&#34;
    self._src = filename
    self._kind = kind
    is_horizontal = self._kind == &#34;horizontal&#34;
    self._id_col = id_col
    self._ct_col = aux.from_kwargs(&#34;ct_col&#34;, None, kwargs, rm = True)
    self._assay_col = aux.from_kwargs(&#34;assay_col&#34;, None, kwargs, rm = True)

    if not is_horizontal:
        # first try default pd.read_csv or read_excel
        self._try_simple_read(**kwargs)

        # check if we got data, and abort if so
        if self._data is not None: 
            self._df = self._data
            self._is_regular = True
            return

    # if haven&#39;t got data, then we go to parsing...

    # set is_horizontal to True for hybrid 
    # tables that are decorated
    if self._kind == &#34;hybrid&#34; and aux.from_kwargs(&#34;decorator&#34;, False, kwargs):
        is_horizontal = True
        self._hybrid_decorated = True

    # setup Parser to get data
    self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

    self._Parser.read(self._src, **kwargs)
    self._Parser.labels(id_label = self._id_col)
    self._Parser._make_BigTable_range(is_horizontal = is_horizontal)
    self._data = self._Parser._bigtable_range</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></b></code>:
<ul class="hlist">
<li><code><a title="qpcr.Readers.Readers.MultiReader.assays" href="#qpcr.Readers.Readers.MultiReader.assays">assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.clear" href="#qpcr.Readers.Readers.MultiReader.clear">clear</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.get" href="#qpcr.Readers.Readers.MultiReader.get">get</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.make_Assay" href="#qpcr.Readers.Readers._CORE_Reader.make_Assay">make_Assay</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.make_Assays" href="#qpcr.Readers.Readers.MultiReader.make_Assays">make_Assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.n" href="#qpcr.Readers.Readers._CORE_Reader.n">n</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.names" href="#qpcr.Readers.Readers._CORE_Reader.names">names</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.normalisers" href="#qpcr.Readers.Readers.MultiReader.normalisers">normalisers</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.replicates" href="#qpcr.Readers.Readers._CORE_Reader.replicates">replicates</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.save_to" href="#qpcr.Readers.Readers.MultiReader.save_to">save_to</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader"><code class="flex name class">
<span>class <span class="ident">MultiReader</span></span>
<span>(</span><span>filename: str = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.</p>
<h2 id="input-data-files">Input Data Files</h2>
<p>Valid input files are multi-assay irregular <code>csv</code> or <code>excel</code> files,
that specify assays by one replicate identifier column and one Ct value column.</p>
<p>Separate assay tables may be either below one another (separated by blank lines!)
or besides one another (requires <code>transpose = True</code>), but ALL in the SAME sheet!</p>
<p>Assays of interest and normaliser assays <em>must</em> be marked using <code>decorators</code>.</p>
<h4 id="example-of-an-irregular-multi-assay-datafile">Example of an "irregular" multi-assay datafile</h4>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Some meta-data here</td>
<td>maybe today's date</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Assay 1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>id</td>
<td>Ct</td>
<td>other_data</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl1</td>
<td>5.67</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl2</td>
<td>5.79</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>&lt;- blank line here!</td>
<td></td>
</tr>
<tr>
<td>Assay 2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>id</td>
<td>Ct</td>
<td>other_data</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl1</td>
<td>10.23</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl2</td>
<td>10.54</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="note">Note</h2>
<p><code><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></code> can transform the extracted datasets directly into <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects using <code><a title="qpcr.Readers.Readers.MultiReader.make_Assays" href="#qpcr.Readers.Readers.MultiReader.make_Assays">MultiReader.make_Assays()</a></code>.
It will perform grouping of assays if possible but will return raw-assays if not! <code>get</code> will either return a dictionary
of the raw dataframes or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code>s.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments that should be passed to the <code>read</code> method which is immediately called during init if a filename is provided.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiReader(SingleReader, aux._ID):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    Input Data Files
    ----------------
    Valid input files are multi-assay irregular `csv` or `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`), but ALL in the SAME sheet!

    Assays of interest and normaliser assays *must* be marked using `decorators`.

    #### Example of an &#34;irregular&#34; multi-assay datafile
    |                     |                    |            |      |      |
    | ------------------- | ------------------ | ---------- | ---- | ---- |
    | Some meta-data here | maybe today&#39;s date |            |      |      |
    |                     |                    |            |      |      |
    | Assay 1             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 5.67               | ...        |      |      |
    | ctrl2               | 5.79               | ...        |      |      |
    | ...                 | ...                |            |      |      |
    |                     |                    |            |   &lt;- blank line here!   |      |
    | Assay 2             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 10.23              | ...        |      |      |
    | ctrl2               | 10.54              | ...        |      |      |
    | ...                 | ...                |            |      |      |

    Note
    ------
    `MultiReader` can transform the extracted datasets directly into `qpcr.Assay` objects using `MultiReader.make_Assays()`.
    It will perform grouping of assays if possible but will return raw-assays if not! `get` will either return a dictionary
    of the raw dataframes or a list of `qpcr.Assay`s.

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
            Any additional keyword arguments that should be passed to the `read` method which is immediately called during init if a filename is provided.
    &#34;&#34;&#34;
    def __init__(self, filename : str = None, **kwargs):
        super(aux._ID, self).__init__()
        self._src = filename
        self._save_loc = None
        self._replicates = None
        self._names = None
        self._Parser = None
        self._assay_pattern = None
        self._assays = {}
        self._normalisers = {}
        if self._src is not None: 
            self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()
            self.read(filename = self._src, **kwargs)

    def clear(self):
        &#34;&#34;&#34;
        Clears all the extracted data from the Reader
        &#34;&#34;&#34;
        self._assays = {}
        self._normalisers = {}

    def assays(self, which : str = None):
        &#34;&#34;&#34;
        Parameters
        ----
        which : str
            If specified it only returns the data for the specified assay.
            Otherwise (default) it returns all assays.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        names : list
            A list of the names of all extracted assays.
        &#34;&#34;&#34;
        return self._get_from_which(self._assays, which)

    def normalisers(self, which : str = None):
        &#34;&#34;&#34;
        Parameters
        ----
        which : str
            If specified it only returns the data for the specified normaliser.
            Otherwise (default) it returns all normalisers.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        names : list
            A list of the names of all extracted normalisers.
        &#34;&#34;&#34;
        return self._get_from_which(self._normalisers, which)

    def get(self, which : str):
        &#34;&#34;&#34;
        Returns the stored assays or normalisers.

        Parameters
        ----------
        which : str
            Can be either `&#34;assays&#34;` or `&#34;normalisers&#34;` or any specific assay identifier.

        Returns
        -------
        data : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if `make_Assays` has not been run yet)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        data = None
        if which == &#34;assays&#34;:
            data = self._assays
        elif which == &#34;normalisers&#34;:
            data = self._normalisers
        else: 
            try:
                data = self._get_from_which(self._assays, which)
            except: 
                data = self._get_from_which(self._normalisers, which)
        return data

    def read(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads a multi-assay datafile with decorated assays. 
        Any non-decorated assays are ignored!

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        **kwargs
                Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
        &#34;&#34;&#34;
        self._src = filename

        # check for a valid input file
        if self._filesuffix() not in supported_filetypes:
            aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

        self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

        # check if file should be read transposed
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            self._Parser.transpose()
        
        # setup a saving location if it was provided
        if self.save_to() is not None: 
            self._Parser.save_to(self.save_to())

        self._Parser.read(self._src, **kwargs)

    def parse(self, **kwargs):
        &#34;&#34;&#34;
        Extracts the datasets (assays) from the read datafile.
        
        Parameters
        ----------
        **kwargs
            Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `parse` method that extracts the datasets.
        &#34;&#34;&#34;
        # check for the two required inputs (either decorator must be specified or assay_pattern)
        # if neither is specified we default to using decorators!  
        decorator = aux.from_kwargs(&#34;decorator&#34;, None, kwargs)
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, None, kwargs)

        # pass kwargs to Parser for setup
        self._prep_parser(kwargs)

        # set up parsing
        if decorator is not None or assay_pattern is None:
            self._parse_by_decorators(**kwargs)
        elif assay_pattern is not None: 
            self._parse_by_pattern(kwargs, assay_pattern)
        else: 
            # ERROR HERE
            aw.SoftWarning(&#34;MultiReader:no_decorator_or_pattern&#34;)
             
    def make_Assays(self):
        &#34;&#34;&#34;
        Convert all found assays and normalisers into `qpcr.Assay` objects.
        &#34;&#34;&#34;
        # convert assays to qpcr.Assay and overwrite current dict by new list
        new_assays = []
        for name, df in self._assays.items():
            new_assay = self._make_new_Assay(name, df)
            new_assays.append(new_assay)
        self._assays = new_assays

        # do the same for normalisers
        new_normalisers = []
        for name, df in self._normalisers.items():
            new_assay = self._make_new_Assay(name, df)
            new_normalisers.append(new_assay)
        self._normalisers = new_normalisers

    def pipe(self, filename :str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assays

        Note 
        ----
        This is the suggested use of `MultiReader`. 
        If a directory has been specified into which the datafiles shall be saved, 
        then saving will automatically be done.

        Parameters
        -------
        filename : str
            A filepath to an input datafile.
        **kwargs
            Any additional keyword argument that will be passed to any of the wrapped methods.
        Returns
        -------
        data : tuple
            A tuple of the found assays-of-interst (first element) and normaliser-assays (second element).
        &#34;&#34;&#34;
        
        # clear previously read data 
        self.clear()

        # read new data
        try: 
            self.read(filename, **kwargs)
        except: 
            self.read(filename)
            aw.SoftWarning(&#34;Parser:incompatible_read_kwargs&#34;, func = f&#34;{type(self._Parser).__name__}&#39;s read method&#34;)
        
        # parse and make assays
        self.parse(**kwargs)
        self.make_Assays()

        # return new data
        assays = self.get( which = &#34;assays&#34; )
        normalisers = self.get( which = &#34;normalisers&#34; )
        return assays, normalisers

    def save_to(self, location : str = None):
        &#34;&#34;&#34;
        Sets the location into which the individual assay datafiles should be saved.
        Parameters
        ----------
        location : str
            The path to a directory where the newly generated assay datafiles shall be saved.
            If this directory does not yet exist, it will be automatically made.
        &#34;&#34;&#34;
        if location is not None: 
            self._save_loc = location
            if not os.path.exists(self._save_loc):
                os.mkdir(self._save_loc)
        return self._save_loc

    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs, rm = True)
        self.replicates(replicates)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        self.names(names)
        data = self.pipe(**kwargs)
        return data


    def _get_from_which(self, dataset, which):
        &#34;&#34;&#34;
        The core for assayS() and normalisers() to get either all or a specific one
        &#34;&#34;&#34;
        if which is not None: 
            if aux.same_type(dataset, {}):
                assay = dataset[which]
            else: 
                assay = [i for i in dataset if i.id() == which][0]
            return assay
        else:
            if aux.same_type(dataset, {}):
                names = dataset.keys()
                assays = dataset.values()
            else:
                names = [i.id() for i in dataset]
                assays = dataset
            return assays, names

    def _parse_by_pattern(self, kwargs, assay_pattern):
        &#34;&#34;&#34;
        Parses the file only based on assay_pattern.
        Note this will also work if a decorator has been specified additionally.
        &#34;&#34;&#34;
        self._Parser.parse( assay_pattern = assay_pattern, **kwargs )
        assays = self._Parser.get()       
        self._assays = assays

    def _parse_by_decorators(self, **kwargs):
        &#34;&#34;&#34;
        Parses the file and idenifies assays and normalisers
        based on decorators
        &#34;&#34;&#34;
        aux.from_kwargs(&#34;decorator&#34;, None, kwargs, rm = True)
        
        # get assays-of-interest
        self._Parser.parse( decorator = &#34;qpcr:assay&#34;, **kwargs )
        assays = self._Parser.get()       
        self._assays = assays

        # save extracted files if so desired...
        if self.save_to() is not None: self._Parser.save()

        # clear results and run again for normalisers
        self._Parser.clear()

        # get normaliser-assays
        self._Parser.parse( decorator = &#34;qpcr:normaliser&#34;, **kwargs )
        normalisers = self._Parser.get()
        self._normalisers = normalisers
        if self.save_to() is not None: self._Parser.save()

    def _prep_parser(self, kwargs):
        &#34;&#34;&#34;
        Passes kwargs to Parser and performs additional setup
        &#34;&#34;&#34;
        # setup assay_patterns if they were provided
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, None, kwargs, rm = True)
        self._Parser.assay_pattern(assay_pattern)

        # check if file should be read transposed
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            self._Parser.transpose()

        # get data column labels
        id_label = aux.from_kwargs(&#34;id_label&#34;, &#34;Name&#34;, kwargs, rm = True)
        ct_label = aux.from_kwargs(&#34;ct_label&#34;, &#34;Ct&#34;, kwargs, rm = True)
        self._Parser.labels(id_label,ct_label)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></li>
<li><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></li>
<li>qpcr._auxiliary._ID</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.BigTableReader" href="#qpcr.Readers.Readers.BigTableReader">BigTableReader</a></li>
<li><a title="qpcr.Readers.Readers.MultiSheetReader" href="#qpcr.Readers.Readers.MultiSheetReader">MultiSheetReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="qpcr.Readers.Readers.MultiReader.assays"><code class="name flex">
<span>def <span class="ident">assays</span></span>(<span>self, which: str = None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>which</code></strong> :&ensp;<code>str</code></dt>
<dd>If specified it only returns the data for the specified assay.
Otherwise (default) it returns all assays.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser
(if <code>make_Assays</code> has not been run yet)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of the names of all extracted assays.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assays(self, which : str = None):
    &#34;&#34;&#34;
    Parameters
    ----
    which : str
        If specified it only returns the data for the specified assay.
        Otherwise (default) it returns all assays.

    Returns
    -------
    data : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser 
        (if `make_Assays` has not been run yet)
        or a list of `qpcr.Assay` objects.
    names : list
        A list of the names of all extracted assays.
    &#34;&#34;&#34;
    return self._get_from_which(self._assays, which)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Clears all the extracted data from the Reader</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self):
    &#34;&#34;&#34;
    Clears all the extracted data from the Reader
    &#34;&#34;&#34;
    self._assays = {}
    self._normalisers = {}</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self, which: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the stored assays or normalisers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>which</code></strong> :&ensp;<code>str</code></dt>
<dd>Can be either <code>"assays"</code> or <code>"normalisers"</code> or any specific assay identifier.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser
(if <code>make_Assays</code> has not been run yet)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self, which : str):
    &#34;&#34;&#34;
    Returns the stored assays or normalisers.

    Parameters
    ----------
    which : str
        Can be either `&#34;assays&#34;` or `&#34;normalisers&#34;` or any specific assay identifier.

    Returns
    -------
    data : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser 
        (if `make_Assays` has not been run yet)
        or a list of `qpcr.Assay` objects.
    &#34;&#34;&#34;
    data = None
    if which == &#34;assays&#34;:
        data = self._assays
    elif which == &#34;normalisers&#34;:
        data = self._normalisers
    else: 
        try:
            data = self._get_from_which(self._assays, which)
        except: 
            data = self._get_from_which(self._normalisers, which)
    return data</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.make_Assays"><code class="name flex">
<span>def <span class="ident">make_Assays</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert all found assays and normalisers into <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_Assays(self):
    &#34;&#34;&#34;
    Convert all found assays and normalisers into `qpcr.Assay` objects.
    &#34;&#34;&#34;
    # convert assays to qpcr.Assay and overwrite current dict by new list
    new_assays = []
    for name, df in self._assays.items():
        new_assay = self._make_new_Assay(name, df)
        new_assays.append(new_assay)
    self._assays = new_assays

    # do the same for normalisers
    new_normalisers = []
    for name, df in self._normalisers.items():
        new_assay = self._make_new_Assay(name, df)
        new_normalisers.append(new_assay)
    self._normalisers = new_normalisers</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.normalisers"><code class="name flex">
<span>def <span class="ident">normalisers</span></span>(<span>self, which: str = None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>which</code></strong> :&ensp;<code>str</code></dt>
<dd>If specified it only returns the data for the specified normaliser.
Otherwise (default) it returns all normalisers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser
(if <code>make_Assays</code> has not been run yet)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of the names of all extracted normalisers.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalisers(self, which : str = None):
    &#34;&#34;&#34;
    Parameters
    ----
    which : str
        If specified it only returns the data for the specified normaliser.
        Otherwise (default) it returns all normalisers.

    Returns
    -------
    data : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser 
        (if `make_Assays` has not been run yet)
        or a list of `qpcr.Assay` objects.
    names : list
        A list of the names of all extracted normalisers.
    &#34;&#34;&#34;
    return self._get_from_which(self._normalisers, which)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts the datasets (assays) from the read datafile.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments that should be passed to the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>''s <code>parse</code> method that extracts the datasets.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(self, **kwargs):
    &#34;&#34;&#34;
    Extracts the datasets (assays) from the read datafile.
    
    Parameters
    ----------
    **kwargs
        Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `parse` method that extracts the datasets.
    &#34;&#34;&#34;
    # check for the two required inputs (either decorator must be specified or assay_pattern)
    # if neither is specified we default to using decorators!  
    decorator = aux.from_kwargs(&#34;decorator&#34;, None, kwargs)
    assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, None, kwargs)

    # pass kwargs to Parser for setup
    self._prep_parser(kwargs)

    # set up parsing
    if decorator is not None or assay_pattern is None:
        self._parse_by_decorators(**kwargs)
    elif assay_pattern is not None: 
        self._parse_by_pattern(kwargs, assay_pattern)
    else: 
        # ERROR HERE
        aw.SoftWarning(&#34;MultiReader:no_decorator_or_pattern&#34;)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.pipe"><code class="name flex">
<span>def <span class="ident">pipe</span></span>(<span>self, filename: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A wrapper for read+parse+make_Assays</p>
<h2 id="note">Note</h2>
<p>This is the suggested use of <code><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></code>.
If a directory has been specified into which the datafiles shall be saved,
then saving will automatically be done.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to an input datafile.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword argument that will be passed to any of the wrapped methods.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>tuple</code></dt>
<dd>A tuple of the found assays-of-interst (first element) and normaliser-assays (second element).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipe(self, filename :str, **kwargs):
    &#34;&#34;&#34;
    A wrapper for read+parse+make_Assays

    Note 
    ----
    This is the suggested use of `MultiReader`. 
    If a directory has been specified into which the datafiles shall be saved, 
    then saving will automatically be done.

    Parameters
    -------
    filename : str
        A filepath to an input datafile.
    **kwargs
        Any additional keyword argument that will be passed to any of the wrapped methods.
    Returns
    -------
    data : tuple
        A tuple of the found assays-of-interst (first element) and normaliser-assays (second element).
    &#34;&#34;&#34;
    
    # clear previously read data 
    self.clear()

    # read new data
    try: 
        self.read(filename, **kwargs)
    except: 
        self.read(filename)
        aw.SoftWarning(&#34;Parser:incompatible_read_kwargs&#34;, func = f&#34;{type(self._Parser).__name__}&#39;s read method&#34;)
    
    # parse and make assays
    self.parse(**kwargs)
    self.make_Assays()

    # return new data
    assays = self.get( which = &#34;assays&#34; )
    normalisers = self.get( which = &#34;normalisers&#34; )
    return assays, normalisers</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, filename: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a multi-assay datafile with decorated assays.
Any non-decorated assays are ignored!</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments that should be passed to the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>''s <code>read</code> method that extracts the datasets.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, filename : str, **kwargs):
    &#34;&#34;&#34;
    Reads a multi-assay datafile with decorated assays. 
    Any non-decorated assays are ignored!

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
            Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
    &#34;&#34;&#34;
    self._src = filename

    # check for a valid input file
    if self._filesuffix() not in supported_filetypes:
        aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

    self._Parser = Parsers.CsvParser() if self._filesuffix() == &#34;csv&#34; else Parsers.ExcelParser()

    # check if file should be read transposed
    transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
    if transpose:
        self._Parser.transpose()
    
    # setup a saving location if it was provided
    if self.save_to() is not None: 
        self._Parser.save_to(self.save_to())

    self._Parser.read(self._src, **kwargs)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiReader.save_to"><code class="name flex">
<span>def <span class="ident">save_to</span></span>(<span>self, location: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the location into which the individual assay datafiles should be saved.
Parameters</p>
<hr>
<dl>
<dt><strong><code>location</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to a directory where the newly generated assay datafiles shall be saved.
If this directory does not yet exist, it will be automatically made.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_to(self, location : str = None):
    &#34;&#34;&#34;
    Sets the location into which the individual assay datafiles should be saved.
    Parameters
    ----------
    location : str
        The path to a directory where the newly generated assay datafiles shall be saved.
        If this directory does not yet exist, it will be automatically made.
    &#34;&#34;&#34;
    if location is not None: 
        self._save_loc = location
        if not os.path.exists(self._save_loc):
            os.mkdir(self._save_loc)
    return self._save_loc</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></b></code>:
<ul class="hlist">
<li><code><a title="qpcr.Readers.Readers.SingleReader.make_Assay" href="#qpcr.Readers.Readers._CORE_Reader.make_Assay">make_Assay</a></code></li>
<li><code><a title="qpcr.Readers.Readers.SingleReader.n" href="#qpcr.Readers.Readers._CORE_Reader.n">n</a></code></li>
<li><code><a title="qpcr.Readers.Readers.SingleReader.names" href="#qpcr.Readers.Readers._CORE_Reader.names">names</a></code></li>
<li><code><a title="qpcr.Readers.Readers.SingleReader.replicates" href="#qpcr.Readers.Readers._CORE_Reader.replicates">replicates</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="qpcr.Readers.Readers.MultiSheetReader"><code class="flex name class">
<span>class <span class="ident">MultiSheetReader</span></span>
</code></dt>
<dd>
<div class="desc"><p>Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.</p>
<h2 id="input-data-files">Input Data Files</h2>
<p>Valid input files are multi-assay irregular <code>excel</code> files,
that specify assays by one replicate identifier column and one Ct value column.</p>
<p>Separate assay tables may be either below one another (separated by blank lines!)
or besides one another (requires <code>transpose = True</code>), but may be in DIFFERENT sheets.
All assays from all sheets will be read!</p>
<p>Assays of interest and normaliser assays <em>must</em> be marked using <code>decorators</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MultiSheetReader(MultiReader):
    &#34;&#34;&#34;
    Reads a single multi-assay datafile and reads assays-of-interest and normaliser-assays based on decorators.
    
    Input Data Files
    ----------------
    Valid input files are multi-assay irregular `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`), but may be in DIFFERENT sheets.
    All assays from all sheets will be read!

    Assays of interest and normaliser assays *must* be marked using `decorators`.


    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()

    def read(self, *args, **kwargs):
        &#34;&#34;&#34;
        The `MultiSheetReader` **only** offers a `pipe` method!
        Hence, neither `read` nor `parse` will work directly!
        &#34;&#34;&#34;
        print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)

    def parse(self, *args, **kwargs):
        &#34;&#34;&#34;
        The `MultiSheetReader` **only** offers a `pipe` method!
        Hence, neither `read` nor `parse` will work directly!
        &#34;&#34;&#34;
        print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)



    def pipe(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads a multi-assay and multi-sheet datafile with decorated assays. 
        Any non-decorated assays are ignored!

        Parameters
        ----------
        filename : str
            A filepath to a raw data file, containing multiple assays that were decorated. 
            Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
        **kwargs
                Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
        
        Returns
        -------
        assays : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        normalisers : dict or list
            Returns either the raw dictionary of dataframes returned by the Parser 
            (if no qpcr.Assays could be made automatically)
            or a list of `qpcr.Assay` objects.
        &#34;&#34;&#34;
        self._src = filename

        # read file to get all sheets
        sheets = pd.read_excel(filename, sheet_name = None)

        all_assays = {}
        all_normalisers = {}
        
        # now repetitively read all sheets and extract data
        reader = MultiReader()
        for sheet in sheets.keys():
            try: 
                # read file and parse data
                kws = deepcopy(kwargs)
                reader.read(filename, sheet_name = sheet)
                reader.parse(ignore_empty = True, **kws)

                # get assays
                assays, normalisers = reader.get(&#34;assays&#34;), reader.get(&#34;normalisers&#34;)
                all_assays.update(assays)
                all_normalisers.update(normalisers)

            except Exception as e: 
                # ERROR HERE
                aw.SoftWarning(&#34;MultiSheetReader:sheet_unreadable&#34;, sheet = sheets, e = e)

        # store data
        self._assays = all_assays
        self._normalisers = all_normalisers

        # try making Assays directly, return dictioanries if not possible...
        try: 
            self.make_Assays()
        except Exception as e:
            print(e)

        assays, normalisers = self._assays, self._normalisers
        return assays, normalisers
        
    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs, rm = True)
        self.replicates(replicates)
        names = aux.from_kwargs(&#34;names&#34;, None, kwargs, rm = True)
        self.names(names)
        data = self.pipe(**kwargs)
        return data</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></li>
<li><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></li>
<li><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></li>
<li>qpcr._auxiliary._ID</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="qpcr.Readers.Readers.MultiSheetReader.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>The <code><a title="qpcr.Readers.Readers.MultiSheetReader" href="#qpcr.Readers.Readers.MultiSheetReader">MultiSheetReader</a></code> <strong>only</strong> offers a <code>pipe</code> method!
Hence, neither <code>read</code> nor <code>parse</code> will work directly!</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(self, *args, **kwargs):
    &#34;&#34;&#34;
    The `MultiSheetReader` **only** offers a `pipe` method!
    Hence, neither `read` nor `parse` will work directly!
    &#34;&#34;&#34;
    print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiSheetReader.pipe"><code class="name flex">
<span>def <span class="ident">pipe</span></span>(<span>self, filename: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a multi-assay and multi-sheet datafile with decorated assays.
Any non-decorated assays are ignored!</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file, containing multiple assays that were decorated.
Check out the documentation of the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>'s to learn more about decorators.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments that should be passed to the <code><a title="qpcr.Parsers" href="../Parsers/index.html">qpcr.Parsers</a></code>''s <code>read</code> method that extracts the datasets.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>assays</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
<dt><strong><code>normalisers</code></strong> :&ensp;<code>dict</code> or <code>list</code></dt>
<dd>Returns either the raw dictionary of dataframes returned by the Parser
(if no qpcr.Assays could be made automatically)
or a list of <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> objects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipe(self, filename : str, **kwargs):
    &#34;&#34;&#34;
    Reads a multi-assay and multi-sheet datafile with decorated assays. 
    Any non-decorated assays are ignored!

    Parameters
    ----------
    filename : str
        A filepath to a raw data file, containing multiple assays that were decorated. 
        Check out the documentation of the `qpcr.Parsers`&#39;s to learn more about decorators.
    **kwargs
            Any additional keyword arguments that should be passed to the `qpcr.Parsers`&#39;&#39;s `read` method that extracts the datasets.
    
    Returns
    -------
    assays : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser (if no qpcr.Assays could be made automatically)
        or a list of `qpcr.Assay` objects.
    normalisers : dict or list
        Returns either the raw dictionary of dataframes returned by the Parser 
        (if no qpcr.Assays could be made automatically)
        or a list of `qpcr.Assay` objects.
    &#34;&#34;&#34;
    self._src = filename

    # read file to get all sheets
    sheets = pd.read_excel(filename, sheet_name = None)

    all_assays = {}
    all_normalisers = {}
    
    # now repetitively read all sheets and extract data
    reader = MultiReader()
    for sheet in sheets.keys():
        try: 
            # read file and parse data
            kws = deepcopy(kwargs)
            reader.read(filename, sheet_name = sheet)
            reader.parse(ignore_empty = True, **kws)

            # get assays
            assays, normalisers = reader.get(&#34;assays&#34;), reader.get(&#34;normalisers&#34;)
            all_assays.update(assays)
            all_normalisers.update(normalisers)

        except Exception as e: 
            # ERROR HERE
            aw.SoftWarning(&#34;MultiSheetReader:sheet_unreadable&#34;, sheet = sheets, e = e)

    # store data
    self._assays = all_assays
    self._normalisers = all_normalisers

    # try making Assays directly, return dictioanries if not possible...
    try: 
        self.make_Assays()
    except Exception as e:
        print(e)

    assays, normalisers = self._assays, self._normalisers
    return assays, normalisers</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.MultiSheetReader.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>The <code><a title="qpcr.Readers.Readers.MultiSheetReader" href="#qpcr.Readers.Readers.MultiSheetReader">MultiSheetReader</a></code> <strong>only</strong> offers a <code>pipe</code> method!
Hence, neither <code>read</code> nor <code>parse</code> will work directly!</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, *args, **kwargs):
    &#34;&#34;&#34;
    The `MultiSheetReader` **only** offers a `pipe` method!
    Hence, neither `read` nor `parse` will work directly!
    &#34;&#34;&#34;
    print(&#34;Sorry, the MultiSheetReader can currently only be used, through it&#39;s pipe() method!&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></b></code>:
<ul class="hlist">
<li><code><a title="qpcr.Readers.Readers.MultiReader.assays" href="#qpcr.Readers.Readers.MultiReader.assays">assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.clear" href="#qpcr.Readers.Readers.MultiReader.clear">clear</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.get" href="#qpcr.Readers.Readers.MultiReader.get">get</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.make_Assay" href="#qpcr.Readers.Readers._CORE_Reader.make_Assay">make_Assay</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.make_Assays" href="#qpcr.Readers.Readers.MultiReader.make_Assays">make_Assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.n" href="#qpcr.Readers.Readers._CORE_Reader.n">n</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.names" href="#qpcr.Readers.Readers._CORE_Reader.names">names</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.normalisers" href="#qpcr.Readers.Readers.MultiReader.normalisers">normalisers</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.replicates" href="#qpcr.Readers.Readers._CORE_Reader.replicates">replicates</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.save_to" href="#qpcr.Readers.Readers.MultiReader.save_to">save_to</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="qpcr.Readers.Readers.SingleReader"><code class="flex name class">
<span>class <span class="ident">SingleReader</span></span>
<span>(</span><span>filename: str = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads qpcr raw data files in csv or excel format to get a single dataset. </p>
<h2 id="input-data-files">Input Data Files</h2>
<p>Valid input files are either regular <code>csv</code> or <code>excel</code> files, or
irregular <code>csv</code> or <code>excel</code> files,
that specify assays by one replicate identifier column and one Ct value column.</p>
<p>Irregular input files may specify multiple assays as separate tables,
one assay has to be selected using the <code>assay</code> argument.
Separate assay tables may be either below one another (separated by blank lines!)
or besides one another (requires <code>transpose = True</code>).</p>
<h4 id="example-of-a-regular-single-assay-datafile">Example of a "regular" single-assay datafile</h4>
<table>
<thead>
<tr>
<th>id</th>
<th>Ct</th>
<th>other data</th>
</tr>
</thead>
<tbody>
<tr>
<td>ctrl1</td>
<td>5.67</td>
<td>&hellip;</td>
</tr>
<tr>
<td>ctrl2</td>
<td>5.79</td>
<td>&hellip;</td>
</tr>
<tr>
<td>ctrl3</td>
<td>5.86</td>
<td>&hellip;</td>
</tr>
<tr>
<td>condA1</td>
<td>5.34</td>
<td>&hellip;</td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td>&hellip;</td>
</tr>
</tbody>
</table>
<h4 id="example-of-an-irregular-single-assay-datafile">Example of an "irregular" single-assay datafile</h4>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Some meta-data here</td>
<td>maybe today's date</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Assay 1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>id</td>
<td>Ct</td>
<td>other_data</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl1</td>
<td>5.67</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ctrl2</td>
<td>5.79</td>
<td>&hellip;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>&hellip;</td>
<td>&hellip;</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="note">Note</h2>
<p>This is the successor of the original <code><a title="qpcr.Reader" href="../index.html#qpcr.Reader">Reader</a></code> (not the <code><a title="qpcr.SampleReader" href="../index.html#qpcr.SampleReader">SampleReader</a></code>!).
Hence, the <code><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></code> will return a pandas DataFrame of the dataset
directly using <code>get</code> but not an <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code>.
An <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> object will be returned after calling <code>make_Assay</code>, however.
Furthermore, if the provided file cannot be read as a "regular" file the Reader will automatically
switch to parsing. However, if your file <em>is</em> a regular input file, you can force regular reading
by passing the argument <code>is_regular = True</code> to the <code>read</code> method, which will prevent parsing and allow
you to figure out why regular reading may have failed instead (the Reader will not
provide further insight into why regular reading failed if it switches to parsing).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file.
If the file is a <code>csv</code> file, it has to have two named columns; one for replicate names, one for Ct values.
Both csv (<code>,</code> spearated) and csv2 (<code>;</code> separated) are accepted.
If the file is an <code>excel</code> file it the relevant sections of the spreadsheet are identified automatically.
But they require identifying headers. By default it is assumed that replicate identifiers and Ct values are
stored in columns named <code>Name</code> and <code>Ct</code> but these can be changed using
the <code>id_label</code> and <code>ct_label</code> arguments that can be passed as kwargs.
Also the assay's <code>id</code> can be set as a kwarg.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Any additional keyword arguments that shall be passed to the <code>read()</code> method which is immediately called during init.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SingleReader(_CORE_Reader):
    &#34;&#34;&#34;
    Reads qpcr raw data files in csv or excel format to get a single dataset. 

    Input Data Files
    ----------------
    Valid input files are either regular `csv` or `excel` files, or  irregular `csv` or `excel` files, 
    that specify assays by one replicate identifier column and one Ct value column.

    Irregular input files may specify multiple assays as separate tables, 
    one assay has to be selected using the `assay` argument. 
    Separate assay tables may be either below one another (separated by blank lines!)
    or besides one another (requires `transpose = True`).

    #### Example of a &#34;regular&#34; single-assay datafile
    |id|Ct| other data |
    |---|---| --- |
    | ctrl1| 5.67 | ... |
    | ctrl2| 5.79 | ... |
    | ctrl3 | 5.86 | ... |
    | condA1 | 5.34 | ... |
    | ... | ... | ... |


    #### Example of an &#34;irregular&#34; single-assay datafile
    |                     |                    |            |      |      |
    | ------------------- | ------------------ | ---------- | ---- | ---- |
    | Some meta-data here | maybe today&#39;s date |            |      |      |
    |                     |                    |            |      |      |
    | Assay 1             |                    |            |      |      |
    | id                  | Ct                 | other_data |      |      |
    | ctrl1               | 5.67               | ...        |      |      |
    | ctrl2               | 5.79               | ...        |      |      |
    | ...                 | ...                |            |      |      |


    Note
    ----
    This is the successor of the original `qpcr.Reader` (not the `qpcr.SampleReader`!).
    Hence, the `SingleReader` will return a pandas DataFrame of the dataset 
    directly using `get` but not an `qpcr.Assay`. 
    An `qpcr.Assay` object will be returned after calling `make_Assay`, however. 
    Furthermore, if the provided file cannot be read as a &#34;regular&#34; file the Reader will automatically
    switch to parsing. However, if your file _is_ a regular input file, you can force regular reading 
    by passing the argument `is_regular = True` to the `read` method, which will prevent parsing and allow 
    you to figure out why regular reading may have failed instead (the Reader will not 
    provide further insight into why regular reading failed if it switches to parsing).

    Parameters
    ----------
    filename : str
        A filepath to a raw data file.
        If the file is a `csv` file, it has to have two named columns; one for replicate names, one for Ct values. 
        Both csv (`,` spearated) and csv2 (`;` separated) are accepted.
        If the file is an `excel` file it the relevant sections of the spreadsheet are identified automatically. 
        But they require identifying headers. By default it is assumed that replicate identifiers and Ct values are
        stored in columns named `Name` and `Ct` but these can be changed using 
        the `id_label` and `ct_label` arguments that can be passed as kwargs. 
        Also the assay&#39;s `id` can be set as a kwarg. 

    **kwargs
        Any additional keyword arguments that shall be passed to the `read()` method which is immediately called during init.
    &#34;&#34;&#34;
    def __init__(self, filename:str = None, **kwargs) -&gt; pd.DataFrame: 
        super().__init__()
        self._src = filename
        self._delimiter = None
        self._header = 0
        if self._src is not None:
            self.read(**kwargs)

    def read(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file.

        Note
        -----
        If the data file is an Excel file replicates and their Ct values will be 
        extracted from the first excel sheet of the file by default. 
        A separate sheet can be specified using `sheet_name`.

        Parameters
        ----------
        filename : str
            A filepath to a raw data file.
            If the file is a `csv` file, it has to have two named columns; one for replicate names, one for Ct values. 
            Both csv (`,` spearated) and csv2 (`;` separated) are accepted.
            If the file is an `excel` file it the relevant sections of the spreadsheet are identified automatically. 
            But they require identifying headers. 
            By default it is assumed that replicate identifiers and Ct values are
            stored in columns named `Name` and `Ct` but these can be changed using 
            the `id_label` and `ct_label` arguments that can be passed as kwargs. 
            Note, if only two columns are present anyway, they are assumed to be Id (1st) and Ct (2nd) column, 
            and inputs for `id_label` and `ct_label` are being ignored!
            The assay&#39;s `id` can be set as a kwarg. By default the filename is adopted as id.  
        &#34;&#34;&#34;
        self._src = filename

        self._replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
        self._names = aux.from_kwargs(&#34;names&#34;, None, kwargs)
        self._header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm = True)

        if self._filesuffix() == &#34;csv&#34;:
            self._delimiter = &#34;;&#34; if self._is_csv2() else &#34;,&#34;
        super().read(**kwargs)

    def pipe(self, filename : str, **kwargs):
        &#34;&#34;&#34;
        A wrapper for read+parse+make_Assay

        Returns
        -------
        assay : qpcr.Assay
            An `qpcr.Assay` object of the extracted data
        &#34;&#34;&#34;
        self.read(filename = filename, **kwargs)
        assay = self.get()
        assay = self.make_Assay()
        return assay

    def _DataReader(self, **kwargs):
        &#34;&#34;&#34;
        The DataReader interacting method
        &#34;&#34;&#34;
        data = self.pipe(**kwargs)
        return data

    def _is_csv2(self):
        &#34;&#34;&#34;
        Tests if csv file is ; delimited (True) or common , (False)
        &#34;&#34;&#34;
        with open(self._src, &#34;r&#34;) as openfile: 
            content = openfile.read()
        if &#34;;&#34; in content: 
            return True
        return False

    def _has_header(self):
        &#34;&#34;&#34;
        Checks if column headers are provided in the data file
        It does so by checking if the second element in the first row is numeric
        if it is numeric (returns None &lt;&lt; False) no headers are presumed. Otherwise
        it returns 0 (as in first row has headers)...
        &#34;&#34;&#34;
        with open(self._src, &#34;r&#34;) as openfile: 
            content = openfile.read().split(&#34;\n&#34;)[0]
            content = content.split(self._delimiter)
        try: 
            second_col = content[1]
            second_col = float(second_col)
        except ValueError:
            return 0 # Headers in row 0
        return None  # no headers</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></li>
<li>qpcr._auxiliary._ID</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="qpcr.Readers.Readers.SingleReader.pipe"><code class="name flex">
<span>def <span class="ident">pipe</span></span>(<span>self, filename: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A wrapper for read+parse+make_Assay</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>assay</code></strong> :&ensp;<code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code></dt>
<dd>An <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> object of the extracted data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipe(self, filename : str, **kwargs):
    &#34;&#34;&#34;
    A wrapper for read+parse+make_Assay

    Returns
    -------
    assay : qpcr.Assay
        An `qpcr.Assay` object of the extracted data
    &#34;&#34;&#34;
    self.read(filename = filename, **kwargs)
    assay = self.get()
    assay = self.make_Assay()
    return assay</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers.SingleReader.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, filename: str, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads the given data file.</p>
<h2 id="note">Note</h2>
<p>If the data file is an Excel file replicates and their Ct values will be
extracted from the first excel sheet of the file by default.
A separate sheet can be specified using <code>sheet_name</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>A filepath to a raw data file.
If the file is a <code>csv</code> file, it has to have two named columns; one for replicate names, one for Ct values.
Both csv (<code>,</code> spearated) and csv2 (<code>;</code> separated) are accepted.
If the file is an <code>excel</code> file it the relevant sections of the spreadsheet are identified automatically.
But they require identifying headers.
By default it is assumed that replicate identifiers and Ct values are
stored in columns named <code>Name</code> and <code>Ct</code> but these can be changed using
the <code>id_label</code> and <code>ct_label</code> arguments that can be passed as kwargs.
Note, if only two columns are present anyway, they are assumed to be Id (1st) and Ct (2nd) column,
and inputs for <code>id_label</code> and <code>ct_label</code> are being ignored!
The assay's <code>id</code> can be set as a kwarg. By default the filename is adopted as id.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, filename : str, **kwargs):
    &#34;&#34;&#34;
    Reads the given data file.

    Note
    -----
    If the data file is an Excel file replicates and their Ct values will be 
    extracted from the first excel sheet of the file by default. 
    A separate sheet can be specified using `sheet_name`.

    Parameters
    ----------
    filename : str
        A filepath to a raw data file.
        If the file is a `csv` file, it has to have two named columns; one for replicate names, one for Ct values. 
        Both csv (`,` spearated) and csv2 (`;` separated) are accepted.
        If the file is an `excel` file it the relevant sections of the spreadsheet are identified automatically. 
        But they require identifying headers. 
        By default it is assumed that replicate identifiers and Ct values are
        stored in columns named `Name` and `Ct` but these can be changed using 
        the `id_label` and `ct_label` arguments that can be passed as kwargs. 
        Note, if only two columns are present anyway, they are assumed to be Id (1st) and Ct (2nd) column, 
        and inputs for `id_label` and `ct_label` are being ignored!
        The assay&#39;s `id` can be set as a kwarg. By default the filename is adopted as id.  
    &#34;&#34;&#34;
    self._src = filename

    self._replicates = aux.from_kwargs(&#34;replicates&#34;, None, kwargs)
    self._names = aux.from_kwargs(&#34;names&#34;, None, kwargs)
    self._header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm = True)

    if self._filesuffix() == &#34;csv&#34;:
        self._delimiter = &#34;;&#34; if self._is_csv2() else &#34;,&#34;
    super().read(**kwargs)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></b></code>:
<ul class="hlist">
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.get" href="#qpcr.Readers.Readers._CORE_Reader.get">get</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.make_Assay" href="#qpcr.Readers.Readers._CORE_Reader.make_Assay">make_Assay</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.n" href="#qpcr.Readers.Readers._CORE_Reader.n">n</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.names" href="#qpcr.Readers.Readers._CORE_Reader.names">names</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.replicates" href="#qpcr.Readers.Readers._CORE_Reader.replicates">replicates</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader"><code class="flex name class">
<span>class <span class="ident">_CORE_Reader</span></span>
</code></dt>
<dd>
<div class="desc"><p>The class handling the core functions of the Reader class.
Both the standard qpcr.Reader as well as the qpcr._Qupid_Reader
inherit from this.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class _CORE_Reader(aux._ID):
    &#34;&#34;&#34;
    The class handling the core functions of the Reader class. 
    Both the standard qpcr.Reader as well as the qpcr._Qupid_Reader
    inherit from this. 
    &#34;&#34;&#34;
    def __init__(self):
        super().__init__()
        self._src = None
        self._delimiter = None
        self._header = 0
        self._df = None
        self._replicates = None
        self._names = None


    def get(self):
        &#34;&#34;&#34;
        Returns
        -------
        data : pd.DataFrame
            The dataframe from the datafile.
        &#34;&#34;&#34;
        return self._df

    def n(self):
        &#34;&#34;&#34;
        Returns
        -------
        n : int
            The number of replicates (entries) in the dataframe.
        &#34;&#34;&#34;
        return len(self._df[raw_col_names[0]])

    def make_Assay(self):
        &#34;&#34;&#34;
        Converts the extracted dataset into an `qpcr.Assay`.
        Returns
        --------
        Assay : qpcr.Assay
            The `qpcr.Assay` from the extracted dataset.
        &#34;&#34;&#34;
        assay = self._make_new_Assay(self.id(), self._df)
        return assay

    def read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file.

        If the data file is an Excel file replicates and their Ct values will be 
        extracted from the first excel sheet of the file. Note, this assumes by default
        that the replicates are headed by the label `&#34;Name&#34;` and the corresponding Ct values
        are headed by the label `&#34;Ct&#34;`. Both labels have to be on the same row. 

        If these labels do not match your excel file, you may
        specify `id_label` and `ct_label` as additional arguments.
        &#34;&#34;&#34;
        suffix = self._filesuffix()
        # check for a valid input file
        if suffix not in supported_filetypes:
            aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

        if suffix == &#34;csv&#34;:
            
            # first try simple read of &#34;regular files&#34;
            try: 
                self._csv_read(**kwargs)
            except Exception as e:

                # users can force-regular reading mode
                is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
                if is_regular:
                    # print out warning
                    print(e)
                    return

                # setup parser
                parser = Parsers.CsvParser()
                self._prep_Parser(kwargs, parser)
                
                assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
                
                # pipe the datafile through the parser
                parser.pipe(self._src, **kwargs)

                # get the data
                self._get_single_assay(parser, assay_of_interest)

        elif suffix == &#34;xlsx&#34;:

            try: 
                self._excel_read(**kwargs)
            except Exception as e:

                # users can force-regular reading mode
                is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
                if is_regular:
                    # print out warning
                    print(e)
                    return

                # setup parser
                parser = Parsers.ExcelParser()
                self._prep_Parser(kwargs, parser)
                
                # check for sheet_name
                sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)

                # store assay-of-interest
                assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
                
                # pipe the datafile through the parser
                parser.read(self._src, sheet_name = sheet_name)
                parser.parse(**kwargs)

                # get the data
                self._get_single_assay(parser, assay_of_interest)

    def names(self, names:(list or dict)):
        &#34;&#34;&#34;
        Set names for replicates groups.

        Parameters
        ----------
        names : list or dict
            Either a `list` (new names without repetitions) or `dict` (key = old name, value = new name) specifying new group names. 
            Group names only need to be specified once, and are applied to all replicate entries.
        &#34;&#34;&#34;
        if names is not None: 
            self._names = names
        return self._names

    def replicates(self, replicates : (int or tuple or str) = None):
        &#34;&#34;&#34;
        Either sets or gets the replicates settings to be used for grouping
        Before they are assigned, replicates are vetted to ensure they cover all data entries.

        Parameters
        ----------
        replicates : int or tuple or str
            Can be an `integer` (equal group sizes, e.g. `3` for triplicates), 
            or a `tuple` (uneven group sizes, e.g. `(3,2,3)` if the second group is only a duplicate). 
            Another method to achieve the same thing is to specify a &#34;formula&#34; as a string of how to create a replicate tuple.
            The allowed structure of such a formula is `n:m,` where `n` is the number of replicates in a group and `m` is the number of times
            this pattern is repeated (if no `:m` is specified `:1` is assumed). So, as an example, if there are 12 groups which are triplicates, but
            at the end there is one which only has a single replicate (like the commonly measured diluent qPCR sample), we could either specify the tuple
            individually as `replicates = (3,3,3,3,3,3,3,3,3,3,3,3,1)` or we use the formula to specify `replicates = &#34;3:12,1&#34;`. Of course, this works for
            any arbitrary setting such as `&#34;3:5,2:5,10,3:12&#34;` (which specifies five triplicates, followed by two duplicates, a single decaplicate, and twelve triplicates again – truly a dataset from another dimension)...
        &#34;&#34;&#34;
        if replicates is not None:
            self._replicates = replicates
        return self._replicates

    def _get_single_assay(self, parser, assay_of_interest):
        &#34;&#34;&#34;
        Gets a single dataset from the Parser
        &#34;&#34;&#34;

        # check if there are multiple datasets
        # and if so, check if we got a specified assay_of_interest
        if len(parser.assays()) &gt; 1:
            
            if assay_of_interest is None: 
                aw.HardWarning(&#34;Reader:cannot_read_multifile&#34;, file = self._src, assays = parser.assays(), traceback = False)
            self._df = parser.get(assay_of_interest)
            self.id_reset()
            self.id(assay_of_interest)

        # if only one assay is present anyway, get that one
        else:

            assay_of_interest = parser.assays()[0]
            self._df = parser.get(assay_of_interest)
            self.id_reset()
            self.id(assay_of_interest)

    def _prep_Parser(self, kwargs, parser):
        transpose = aux.from_kwargs(&#34;transpose&#34;, False, kwargs, rm = True)
        if transpose:
            parser.transpose()
                
        # setup patterns and store assay-of-interest
        assay_pattern = aux.from_kwargs(&#34;assay_pattern&#34;, &#34;Rotor-Gene&#34;, kwargs)
        parser.assay_pattern(assay_pattern)
                
        # get data column labels
        id_label = aux.from_kwargs(&#34;id_label&#34;, &#34;Name&#34;, kwargs, rm = True)
        ct_label = aux.from_kwargs(&#34;ct_label&#34;, &#34;Ct&#34;, kwargs, rm = True)
        parser.labels(id_label,ct_label)
  
    def _csv_read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file if it&#39;s a csv file

        This is the basic default reading method for 
        regular csv files.
        &#34;&#34;&#34;
        df = None
        # header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm  = True)
        try: 
            df = pd.read_csv(
                                self._src, 
                                sep = self._delimiter, 
                                header = self._header, 
                                # names = raw_col_names
                            )
        except: 
            aw.HardWarning(&#34;Reader:cannot_read_csv&#34;, file = self._src)


        # try to get a FileID, from the kwargs
        # if that fails, try to get the one from fileID
        id = aux.from_kwargs(&#34;id&#34;, None, kwargs, rm = True)
        if id is not None:
            self.id_reset()
            self.id(id)
        elif isinstance(self._src, str):
            self.id_reset()
            self.id(aux.fileID(self._src))
        
        # vet and crop the dataframe where necessary
        df = self._vet_single_assay_df(kwargs, df)

        self._df = df

    def _excel_read(self, **kwargs):
        &#34;&#34;&#34;
        Reads the given data file if it&#39;s an excel file

        This is the basic default reading method for 
        regular excel files.
        &#34;&#34;&#34;
        df = None
        sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)
        # header = aux.from_kwargs(&#34;header&#34;, 0, kwargs, rm  = True)
        try: 
            df = pd.read_excel(
                                self._src, 
                                sheet_name = sheet_name, 
                                header = self._header, 
                                # names = raw_col_names
                            )
        except: 
            aw.HardWarning(&#34;Reader:cannot_read_csv&#34;, file = self._src)


        # try to get a FileID, from the kwargs
        # if that fails, try to get the one from fileID
        id = aux.from_kwargs(&#34;id&#34;, None, kwargs, rm = True)
        if id is not None:
            self.id_reset()
            self.id(id)
        elif isinstance(self._src, str):
            self.id_reset()
            self.id(aux.fileID(self._src))

        # vet and crop the dataframe where necessary
        df = self._vet_single_assay_df(kwargs, df)

        self._df = df

    def _vet_single_assay_df(self, kwargs, df):
        &#34;&#34;&#34;
        Vets that both Id and Ct columns are present in the data 
        and if so crops the df to the relevant columns, or checks if 
        only two columns are present anyway and then assumes Id+Ct as these two.
        &#34;&#34;&#34;
        
        # check if we got exactly two columns only
        if len( df.columns ) == 2:

            # just get the current column names for later renaming
            Id, Ct = df.columns

        else: 

            # check if a valid Ct column was found
            Ct = aux.from_kwargs( &#34;ct_label&#34;, default_ct_header, kwargs )
            Id = aux.from_kwargs( &#34;id_label&#34;, default_id_header, kwargs )
            
            valid_data = Ct in df.columns and Id in df.columns
            if not valid_data:
                aw.HardWarning(&#34;Reader:cannot_find_datacols&#34;, id_label = Id, ct_label = Ct)
            else:
                # get only the relevant data columns 
                df = df[[Id, Ct]]

        # make sure to convert Ct values to float
        tmp_parser = Parsers.CsvParser()
        Ct_col = df[Ct].to_numpy()
        df[Ct] = tmp_parser._convert_to_numeric(self.id(), Ct_col)

        # rename to qpcr default headers (id + Ct)
        df = df.rename( columns = { Id : raw_col_names[0] , Ct : raw_col_names[1] }  )
        return df

    def _filesuffix(self):
        &#34;&#34;&#34;
        Returns the file-suffix of the provided file
        &#34;&#34;&#34;
        try: 
            suffix = self._src.split(&#34;.&#34;)[-1]
            return suffix
        except: 
            pass

    def _make_new_Assay(self, name, df):
        &#34;&#34;&#34;
        Makes a new Assay object and performs group() already...
        &#34;&#34;&#34;
        new_assay = qpcr.Assay(
                                df = df, 
                                id = name, 
                                replicates = self._replicates,
                                group_names = self._names
                            )
        return new_assay</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>qpcr._auxiliary._ID</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="qpcr.Readers.Readers._CORE_Reader.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>The dataframe from the datafile.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self):
    &#34;&#34;&#34;
    Returns
    -------
    data : pd.DataFrame
        The dataframe from the datafile.
    &#34;&#34;&#34;
    return self._df</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader.make_Assay"><code class="name flex">
<span>def <span class="ident">make_Assay</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the extracted dataset into an <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code>.
Returns</p>
<hr>
<dl>
<dt><strong><code>Assay</code></strong> :&ensp;<code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code></dt>
<dd>The <code><a title="qpcr.Assay" href="../index.html#qpcr.Assay">Assay</a></code> from the extracted dataset.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_Assay(self):
    &#34;&#34;&#34;
    Converts the extracted dataset into an `qpcr.Assay`.
    Returns
    --------
    Assay : qpcr.Assay
        The `qpcr.Assay` from the extracted dataset.
    &#34;&#34;&#34;
    assay = self._make_new_Assay(self.id(), self._df)
    return assay</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader.n"><code class="name flex">
<span>def <span class="ident">n</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of replicates (entries) in the dataframe.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n(self):
    &#34;&#34;&#34;
    Returns
    -------
    n : int
        The number of replicates (entries) in the dataframe.
    &#34;&#34;&#34;
    return len(self._df[raw_col_names[0]])</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader.names"><code class="name flex">
<span>def <span class="ident">names</span></span>(<span>self, names: list)</span>
</code></dt>
<dd>
<div class="desc"><p>Set names for replicates groups.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>names</code></strong> :&ensp;<code>list</code> or <code>dict</code></dt>
<dd>Either a <code>list</code> (new names without repetitions) or <code>dict</code> (key = old name, value = new name) specifying new group names.
Group names only need to be specified once, and are applied to all replicate entries.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def names(self, names:(list or dict)):
    &#34;&#34;&#34;
    Set names for replicates groups.

    Parameters
    ----------
    names : list or dict
        Either a `list` (new names without repetitions) or `dict` (key = old name, value = new name) specifying new group names. 
        Group names only need to be specified once, and are applied to all replicate entries.
    &#34;&#34;&#34;
    if names is not None: 
        self._names = names
    return self._names</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads the given data file.</p>
<p>If the data file is an Excel file replicates and their Ct values will be
extracted from the first excel sheet of the file. Note, this assumes by default
that the replicates are headed by the label <code>"Name"</code> and the corresponding Ct values
are headed by the label <code>"Ct"</code>. Both labels have to be on the same row. </p>
<p>If these labels do not match your excel file, you may
specify <code>id_label</code> and <code>ct_label</code> as additional arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, **kwargs):
    &#34;&#34;&#34;
    Reads the given data file.

    If the data file is an Excel file replicates and their Ct values will be 
    extracted from the first excel sheet of the file. Note, this assumes by default
    that the replicates are headed by the label `&#34;Name&#34;` and the corresponding Ct values
    are headed by the label `&#34;Ct&#34;`. Both labels have to be on the same row. 

    If these labels do not match your excel file, you may
    specify `id_label` and `ct_label` as additional arguments.
    &#34;&#34;&#34;
    suffix = self._filesuffix()
    # check for a valid input file
    if suffix not in supported_filetypes:
        aw.HardWarning(&#34;MultiReader:empty_data&#34;, file = self._src)

    if suffix == &#34;csv&#34;:
        
        # first try simple read of &#34;regular files&#34;
        try: 
            self._csv_read(**kwargs)
        except Exception as e:

            # users can force-regular reading mode
            is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
            if is_regular:
                # print out warning
                print(e)
                return

            # setup parser
            parser = Parsers.CsvParser()
            self._prep_Parser(kwargs, parser)
            
            assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
            
            # pipe the datafile through the parser
            parser.pipe(self._src, **kwargs)

            # get the data
            self._get_single_assay(parser, assay_of_interest)

    elif suffix == &#34;xlsx&#34;:

        try: 
            self._excel_read(**kwargs)
        except Exception as e:

            # users can force-regular reading mode
            is_regular = aux.from_kwargs(&#34;is_regular&#34;, False, kwargs, rm= True)
            if is_regular:
                # print out warning
                print(e)
                return

            # setup parser
            parser = Parsers.ExcelParser()
            self._prep_Parser(kwargs, parser)
            
            # check for sheet_name
            sheet_name = aux.from_kwargs(&#34;sheet_name&#34;, 0, kwargs, rm = True)

            # store assay-of-interest
            assay_of_interest = aux.from_kwargs(&#34;assay&#34;, None, kwargs, rm=True)
            
            # pipe the datafile through the parser
            parser.read(self._src, sheet_name = sheet_name)
            parser.parse(**kwargs)

            # get the data
            self._get_single_assay(parser, assay_of_interest)</code></pre>
</details>
</dd>
<dt id="qpcr.Readers.Readers._CORE_Reader.replicates"><code class="name flex">
<span>def <span class="ident">replicates</span></span>(<span>self, replicates: int = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Either sets or gets the replicates settings to be used for grouping
Before they are assigned, replicates are vetted to ensure they cover all data entries.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>replicates</code></strong> :&ensp;<code>int</code> or <code>tuple</code> or <code>str</code></dt>
<dd>Can be an <code>integer</code> (equal group sizes, e.g. <code>3</code> for triplicates),
or a <code>tuple</code> (uneven group sizes, e.g. <code>(3,2,3)</code> if the second group is only a duplicate).
Another method to achieve the same thing is to specify a "formula" as a string of how to create a replicate tuple.
The allowed structure of such a formula is <code>n:m,</code> where <code>n</code> is the number of replicates in a group and <code>m</code> is the number of times
this pattern is repeated (if no <code>:m</code> is specified <code>:1</code> is assumed). So, as an example, if there are 12 groups which are triplicates, but
at the end there is one which only has a single replicate (like the commonly measured diluent qPCR sample), we could either specify the tuple
individually as <code>replicates = (3,3,3,3,3,3,3,3,3,3,3,3,1)</code> or we use the formula to specify <code>replicates = "3:12,1"</code>. Of course, this works for
any arbitrary setting such as <code>"3:5,2:5,10,3:12"</code> (which specifies five triplicates, followed by two duplicates, a single decaplicate, and twelve triplicates again – truly a dataset from another dimension)&hellip;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replicates(self, replicates : (int or tuple or str) = None):
    &#34;&#34;&#34;
    Either sets or gets the replicates settings to be used for grouping
    Before they are assigned, replicates are vetted to ensure they cover all data entries.

    Parameters
    ----------
    replicates : int or tuple or str
        Can be an `integer` (equal group sizes, e.g. `3` for triplicates), 
        or a `tuple` (uneven group sizes, e.g. `(3,2,3)` if the second group is only a duplicate). 
        Another method to achieve the same thing is to specify a &#34;formula&#34; as a string of how to create a replicate tuple.
        The allowed structure of such a formula is `n:m,` where `n` is the number of replicates in a group and `m` is the number of times
        this pattern is repeated (if no `:m` is specified `:1` is assumed). So, as an example, if there are 12 groups which are triplicates, but
        at the end there is one which only has a single replicate (like the commonly measured diluent qPCR sample), we could either specify the tuple
        individually as `replicates = (3,3,3,3,3,3,3,3,3,3,3,3,1)` or we use the formula to specify `replicates = &#34;3:12,1&#34;`. Of course, this works for
        any arbitrary setting such as `&#34;3:5,2:5,10,3:12&#34;` (which specifies five triplicates, followed by two duplicates, a single decaplicate, and twelve triplicates again – truly a dataset from another dimension)...
    &#34;&#34;&#34;
    if replicates is not None:
        self._replicates = replicates
    return self._replicates</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">

<a href="https://github.com/NoahHenrikKleinschmidt/qpcr">
<img src="../qpcr_light.svg" width = "100%" >
</a>
<h1>Index</h1>

<div class="toc">
<ul>
<li><a href="#available-data-readers">Available Data Readers</a><ul>
<li><a href="#singlereader">SingleReader</a></li>
<li><a href="#multireader">MultiReader</a></li>
<li><a href="#multisheetreader">MultiSheetReader</a></li>
<li><a href="#bigtablereader">BigTableReader</a></li>
<li><a href="#kwarg-incompatibility-warning">Kwarg incompatibility Warning</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="qpcr.Readers" href="index.html">qpcr.Readers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="qpcr.Readers.Readers.BigTableReader" href="#qpcr.Readers.Readers.BigTableReader">BigTableReader</a></code></h4>
<ul class="">
<li><code><a title="qpcr.Readers.Readers.BigTableReader.parse" href="#qpcr.Readers.Readers.BigTableReader.parse">parse</a></code></li>
<li><code><a title="qpcr.Readers.Readers.BigTableReader.pipe" href="#qpcr.Readers.Readers.BigTableReader.pipe">pipe</a></code></li>
<li><code><a title="qpcr.Readers.Readers.BigTableReader.read" href="#qpcr.Readers.Readers.BigTableReader.read">read</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="qpcr.Readers.Readers.MultiReader" href="#qpcr.Readers.Readers.MultiReader">MultiReader</a></code></h4>
<ul class="two-column">
<li><code><a title="qpcr.Readers.Readers.MultiReader.assays" href="#qpcr.Readers.Readers.MultiReader.assays">assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.clear" href="#qpcr.Readers.Readers.MultiReader.clear">clear</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.get" href="#qpcr.Readers.Readers.MultiReader.get">get</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.make_Assays" href="#qpcr.Readers.Readers.MultiReader.make_Assays">make_Assays</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.normalisers" href="#qpcr.Readers.Readers.MultiReader.normalisers">normalisers</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.parse" href="#qpcr.Readers.Readers.MultiReader.parse">parse</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.pipe" href="#qpcr.Readers.Readers.MultiReader.pipe">pipe</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.read" href="#qpcr.Readers.Readers.MultiReader.read">read</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiReader.save_to" href="#qpcr.Readers.Readers.MultiReader.save_to">save_to</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="qpcr.Readers.Readers.MultiSheetReader" href="#qpcr.Readers.Readers.MultiSheetReader">MultiSheetReader</a></code></h4>
<ul class="">
<li><code><a title="qpcr.Readers.Readers.MultiSheetReader.parse" href="#qpcr.Readers.Readers.MultiSheetReader.parse">parse</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiSheetReader.pipe" href="#qpcr.Readers.Readers.MultiSheetReader.pipe">pipe</a></code></li>
<li><code><a title="qpcr.Readers.Readers.MultiSheetReader.read" href="#qpcr.Readers.Readers.MultiSheetReader.read">read</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="qpcr.Readers.Readers.SingleReader" href="#qpcr.Readers.Readers.SingleReader">SingleReader</a></code></h4>
<ul class="">
<li><code><a title="qpcr.Readers.Readers.SingleReader.pipe" href="#qpcr.Readers.Readers.SingleReader.pipe">pipe</a></code></li>
<li><code><a title="qpcr.Readers.Readers.SingleReader.read" href="#qpcr.Readers.Readers.SingleReader.read">read</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="qpcr.Readers.Readers._CORE_Reader" href="#qpcr.Readers.Readers._CORE_Reader">_CORE_Reader</a></code></h4>
<ul class="two-column">
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.get" href="#qpcr.Readers.Readers._CORE_Reader.get">get</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.make_Assay" href="#qpcr.Readers.Readers._CORE_Reader.make_Assay">make_Assay</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.n" href="#qpcr.Readers.Readers._CORE_Reader.n">n</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.names" href="#qpcr.Readers.Readers._CORE_Reader.names">names</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.read" href="#qpcr.Readers.Readers._CORE_Reader.read">read</a></code></li>
<li><code><a title="qpcr.Readers.Readers._CORE_Reader.replicates" href="#qpcr.Readers.Readers._CORE_Reader.replicates">replicates</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>